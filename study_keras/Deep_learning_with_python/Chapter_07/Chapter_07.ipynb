{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7장 딥러닝을 위한 고급 도구\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Sequential 모델을 넘어서 : 케라스의 함수형 API\n",
    "\n",
    "지금까지 모든 신경망은 Sequential 모델을 사용하여 만듬\n",
    "\n",
    "일부 네트워크는 개별 입력이 여러 개 필요하거나 출력이 여러 개 필요. 층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크도 있다.\n",
    "\n",
    "다중 입력 모델 예시\n",
    "- 모듈 병합\n",
    "  - 완전 연결 모듈 - 메타데이터\n",
    "  - RNN 모듈 - 텍스트 설명\n",
    "  - 컨브넷 모듈 - 사진\n",
    "- 가중치를 구해서 가격 예측\n",
    "\n",
    "최근에 개발된 많은 신경망 구조는 선형적이지 않은 네트워크 토폴로지(topology)가 필요\n",
    "- 빈순환 유향 그래프 같은 네트워크 구조\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Bo_Zhao48/publication/312515254/figure/fig3/AS:489373281067012@1493687090916/nception-module-of-GoogLeNet-This-figure-is-from-the-original-paper-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근에는 모델에 잔차 연결을 추가하는 경향도 있음\n",
    "\n",
    "![alt text](https://miro.medium.com/max/6652/1*OFfO8VzLv8GNFNRKafvB7w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 경우는 케라스의 Sequential 클래스를 사용해서는 만들지 못 함\n",
    "\n",
    "함수형 API를 사용하여 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 함수형 API 소개\n",
    "\n",
    "함수형 API에서는 직접 텐서들의 입출력을 다룸\n",
    "- 함수처럼 층을 사용하여 텐서를 입력받고 출력함 -> 그래서 함수형 API라고 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32, )) # 텐서\n",
    "dense = layers.Dense(32, activation='relu') # 함수처럼 사용하기 위해 층 객체를 만듬\n",
    "\n",
    "output_tensor = dense(input_tensor) # 텐서와 함께 층을 호출하면 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential 모델과 함수형 API로 만든 동일한 모델을 나란히 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64, )))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 함수형 API를 만든 모델\n",
    "input_tensor = Input(shape=(64, ))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 입력과 출력 텐서를 지정하여 Model 클래스의 객체를 만듬\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 12.2830\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 14.2161\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 17.6463\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 12us/step - loss: 22.1052\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 27.7020\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 34.2840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 41.4813\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 49.6167\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 13us/step - loss: 58.7254\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 9us/step - loss: 68.8574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc761b636d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', loss='categorical_crossentropy'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 35us/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.94670776367188"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 다중 입력 모델\n",
    "\n",
    "함수형 API는 다중 입력 모델을 만든느 데 사용할 수 있다ㅏ.\n",
    "\n",
    "일반적으로 이런 모델은 서로 다른 입력 가지를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용\n",
    "- 텐서를 더하거나 이어 붙이는 식\n",
    "\n",
    "```python\n",
    "keras.layers.add, keras.layers.concatenate\n",
    "```\n",
    "\n",
    "question-answering 모델을 이용해서 확인해보자\n",
    "- 질문-응답 모델은 2개의 입력을 가짐\n",
    "- 하나는 자연어 질문, 또 하나는 답변에 필요한 정보가 담겨 있는 텍스트(예를 들어 뉴스 기사)\n",
    "- 가장 간단한 구조는 미리 정의한 어휘 사전에서 소프트맥스 함수를 통해 한 단어로 된 답을 출력\n",
    "\n",
    "\n",
    "응답\n",
    "- Dense\n",
    "- concatenate\n",
    "  - LSTM - Embedding - 참고 텍스트\n",
    "  - LSTM - Embedding - 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_voca_size = 10000\n",
    "question_voca_size = 10000\n",
    "answer_voca_size = 500\n",
    "\n",
    "# 텍스트 입력은 길이가 정해지지 않은 정수 시퀀스. 입력 이름을 지정할 수 있다.\n",
    "text_input = Input(shape=(None, ), dtype='int32', name='text')\n",
    "\n",
    "# 입력을 크기가 64인 벡터의 시퀀스로 임베딩\n",
    "embedded_text = layers.Embedding(text_voca_size, 64)(text_input)\n",
    "\n",
    "# LSTM을 사용하여 이 벡터들을 하나의 벡터로 인코딩\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_voca_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# 인코딩된 질문과 텍스트를 연결\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_voca_size, activation='softmax')(concatenated)\n",
    "\n",
    "# 모델 객체를 만들고 2개의 입력과 출력을 주입\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 32)           12416       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 16)           3136        embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48)           0           lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 입력이 2개인데 어떻게 훈련을 할까? 두 가지 방법이 존재\n",
    "- 넘파이 배열의 리스트를 주입\n",
    "- 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 6.2145 - acc: 0.0010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 6.1977 - acc: 0.0490\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 466us/step - loss: 6.1580 - acc: 0.0270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 6.0533 - acc: 0.0030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 460us/step - loss: 5.9919 - acc: 0.0050\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 5.8978 - acc: 0.0080\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 5.7944 - acc: 0.0160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 5.7109 - acc: 0.0320\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 489us/step - loss: 5.6324 - acc: 0.0430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 485us/step - loss: 5.5466 - acc: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc7490313d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 랜덤한 넘파이 데이터를 생성\n",
    "text = np.random.randint(1, text_voca_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_voca_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_voca_size, size=num_samples)\n",
    "# 답은 정수가 아닌 원-핫 인코딩된 벡터\n",
    "answers = to_categorical(answers)\n",
    "\n",
    "# 리스트 입력을 사용하여 학습\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# model.fit({'text' : text, 'question' : question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.3 다중 출력 모델\n",
    "\n",
    "다중 출력 모델을 만들어 보자\n",
    "- 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준 등을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    163968      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    327936      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "voca_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None, ), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(voca_size, 256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 출력 중에 이름을 지정\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 훈련하려면 네트워크 출력마다 다른 손실 함수를 지정해야함\n",
    "- 손실 값을 합치는 가장 간단한 방법은 모두 더하는 것\n",
    "- compile 메소드를 이용해서 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "# model.compile(optimizer='rmsprop', loss={'age' : 'mse', 'income' : 'categorical_crossentropy', 'gender' : 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화 함\n",
    "- 다른 작업들은 손해를 입음\n",
    "- 이를 해결하기 위해 손실 값이 최종 손실에 기여하는 수준을 지정할 수 있음\n",
    "  - 손실 값의 스케일이 다를 때 유용\n",
    "- mse는 일반적으로 3~5사이의 값을 가짐, 성별 분류는 0.1\n",
    "  - 각각 0.25, 10의 가중치를 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "    loss_weight=[0.25, 1., 10.]\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='rmsprop', \n",
    "#     loss={'age' : 'mse', 'income' : 'categorical_crossentropy', 'gender' : 'binary_crossentropy'},\n",
    "#     loss_weight={\n",
    "#         'age':0.25,\n",
    "#         'income' : 1.,\n",
    "#         'gender' : 10.\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 있다고 가정하고 짠 코드\n",
    "\n",
    "# model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.4 층으로 구성된 비순환 유향 그래프(DAG)\n",
    "\n",
    "함수형 API를 사용하면 다중 입력이나 다중 출력 모델뿐만 아니라 내부 토폴로지가 복잡한 네트워크도 만들 수 있다.\n",
    "- 비순환 유향 그래프(DAG)\n",
    "- 비순환이라는 것이 중요\n",
    "  - 다시 말해 이 그래프는 원형을 띨 수 없음 -> 텐서 x가 자기 자신을 출력하는 층의 입력이 될 수 없다.\n",
    "  - 만들 수 있는 루프(순환 연결)는 순환 층의 내부에 있는 것뿐\n",
    "\n",
    "가장 유명한 2개는 인셉션 모듈과 잔차 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인셉션 모듈\n",
    "\n",
    "Inception은 합성곱 신경망에서 인기 있는 네트워크 구조\n",
    "- 네트워크 안의 네트워크라는 구조에 영감을 받은 구조\n",
    "- 가장 기본적인 인셉션 모듈 형태는 3~4개의 가지를 가짐\n",
    "- 네트워크가 따로따로 공간 특성과 채널 방향의 특성을 학습하도록 도움\n",
    "- 한꺼번에 학습하는 것보다 효과가 더 높음\n",
    "  - 더 복잡한 인셉션은 풀링 연산, 여러가지 합성곱 사이즈, 공간 합성곱이 없는 가지 등등\n",
    "\n",
    "![alt text](https://images.deepai.org/django-summernote/2019-06-18/2cec735b-2347-4ded-ae2b-e8a8384f7b46.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D 텐서가 입력된다고 가정\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "# 모든 가지는 동일한 스트라이드(2)를 사용. 출력 크기를 동일하게 만들어 하나로 합치기 위함\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "\n",
    "# axis=-1은 현재 배열의 마지막 axis를 의미합니다.\n",
    "# http://taewan.kim/post/numpy_cheat_sheet/\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.applications.inception_v3.InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
