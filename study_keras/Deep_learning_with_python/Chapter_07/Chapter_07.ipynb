{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7장 딥러닝을 위한 고급 도구\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Sequential 모델을 넘어서 : 케라스의 함수형 API\n",
    "\n",
    "지금까지 모든 신경망은 Sequential 모델을 사용하여 만듬\n",
    "\n",
    "일부 네트워크는 개별 입력이 여러 개 필요하거나 출력이 여러 개 필요. 층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크도 있다.\n",
    "\n",
    "다중 입력 모델 예시\n",
    "- 모듈 병합\n",
    "  - 완전 연결 모듈 - 메타데이터\n",
    "  - RNN 모듈 - 텍스트 설명\n",
    "  - 컨브넷 모듈 - 사진\n",
    "- 가중치를 구해서 가격 예측\n",
    "\n",
    "최근에 개발된 많은 신경망 구조는 선형적이지 않은 네트워크 토폴로지(topology)가 필요\n",
    "- 빈순환 유향 그래프 같은 네트워크 구조\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Bo_Zhao48/publication/312515254/figure/fig3/AS:489373281067012@1493687090916/nception-module-of-GoogLeNet-This-figure-is-from-the-original-paper-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최근에는 모델에 잔차 연결을 추가하는 경향도 있음\n",
    "\n",
    "![alt text](https://miro.medium.com/max/6652/1*OFfO8VzLv8GNFNRKafvB7w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 경우는 케라스의 Sequential 클래스를 사용해서는 만들지 못 함\n",
    "\n",
    "함수형 API를 사용하여 만들 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.1 함수형 API 소개\n",
    "\n",
    "함수형 API에서는 직접 텐서들의 입출력을 다룸\n",
    "- 함수처럼 층을 사용하여 텐서를 입력받고 출력함 -> 그래서 함수형 API라고 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32, )) # 텐서\n",
    "dense = layers.Dense(32, activation='relu') # 함수처럼 사용하기 위해 층 객체를 만듬\n",
    "\n",
    "output_tensor = dense(input_tensor) # 텐서와 함께 층을 호출하면 텐서를 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential 모델과 함수형 API로 만든 동일한 모델을 나란히 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64, )))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 함수형 API를 만든 모델\n",
    "input_tensor = Input(shape=(64, ))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# 입력과 출력 텐서를 지정하여 Model 클래스의 객체를 만듬\n",
    "model = Model(input_tensor, output_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 12.2830\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 14.2161\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 10us/step - loss: 17.6463\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 12us/step - loss: 22.1052\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 27.7020\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 34.2840\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 11us/step - loss: 41.4813\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 49.6167\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 13us/step - loss: 58.7254\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 9us/step - loss: 68.8574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc761b636d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', loss='categorical_crossentropy'\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 35us/step\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.94670776367188"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.2 다중 입력 모델\n",
    "\n",
    "함수형 API는 다중 입력 모델을 만든느 데 사용할 수 있다ㅏ.\n",
    "\n",
    "일반적으로 이런 모델은 서로 다른 입력 가지를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용\n",
    "- 텐서를 더하거나 이어 붙이는 식\n",
    "\n",
    "```python\n",
    "keras.layers.add, keras.layers.concatenate\n",
    "```\n",
    "\n",
    "question-answering 모델을 이용해서 확인해보자\n",
    "- 질문-응답 모델은 2개의 입력을 가짐\n",
    "- 하나는 자연어 질문, 또 하나는 답변에 필요한 정보가 담겨 있는 텍스트(예를 들어 뉴스 기사)\n",
    "- 가장 간단한 구조는 미리 정의한 어휘 사전에서 소프트맥스 함수를 통해 한 단어로 된 답을 출력\n",
    "\n",
    "\n",
    "응답\n",
    "- Dense\n",
    "- concatenate\n",
    "  - LSTM - Embedding - 참고 텍스트\n",
    "  - LSTM - Embedding - 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_voca_size = 10000\n",
    "question_voca_size = 10000\n",
    "answer_voca_size = 500\n",
    "\n",
    "# 텍스트 입력은 길이가 정해지지 않은 정수 시퀀스. 입력 이름을 지정할 수 있다.\n",
    "text_input = Input(shape=(None, ), dtype='int32', name='text')\n",
    "\n",
    "# 입력을 크기가 64인 벡터의 시퀀스로 임베딩\n",
    "embedded_text = layers.Embedding(text_voca_size, 64)(text_input)\n",
    "\n",
    "# LSTM을 사용하여 이 벡터들을 하나의 벡터로 인코딩\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "question_input = Input(shape=(None, ), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_voca_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# 인코딩된 질문과 텍스트를 연결\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "answer = layers.Dense(answer_voca_size, activation='softmax')(concatenated)\n",
    "\n",
    "# 모델 객체를 만들고 2개의 입력과 출력을 주입\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 32)           12416       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 16)           3136        embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48)           0           lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 500)          24500       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 입력이 2개인데 어떻게 훈련을 할까? 두 가지 방법이 존재\n",
    "- 넘파이 배열의 리스트를 주입\n",
    "- 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 주입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 6.2145 - acc: 0.0010\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 518us/step - loss: 6.1977 - acc: 0.0490\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 466us/step - loss: 6.1580 - acc: 0.0270\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 6.0533 - acc: 0.0030\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 460us/step - loss: 5.9919 - acc: 0.0050\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 5.8978 - acc: 0.0080\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 5.7944 - acc: 0.0160\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 5.7109 - acc: 0.0320\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 489us/step - loss: 5.6324 - acc: 0.0430\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 485us/step - loss: 5.5466 - acc: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc7490313d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "# 랜덤한 넘파이 데이터를 생성\n",
    "text = np.random.randint(1, text_voca_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_voca_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_voca_size, size=num_samples)\n",
    "# 답은 정수가 아닌 원-핫 인코딩된 벡터\n",
    "answers = to_categorical(answers)\n",
    "\n",
    "# 리스트 입력을 사용하여 학습\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# model.fit({'text' : text, 'question' : question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.3 다중 출력 모델\n",
    "\n",
    "다중 출력 모델을 만들어 보자\n",
    "- 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준 등을 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    163968      embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 256)    327936      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,146,316\n",
      "Trainable params: 14,146,316\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "voca_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None, ), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(voca_size, 256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPool1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# 출력 중에 이름을 지정\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 훈련하려면 네트워크 출력마다 다른 손실 함수를 지정해야함\n",
    "- 손실 값을 합치는 가장 간단한 방법은 모두 더하는 것\n",
    "- compile 메소드를 이용해서 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "# model.compile(optimizer='rmsprop', loss={'age' : 'mse', 'income' : 'categorical_crossentropy', 'gender' : 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 값이 많이 불균형하면 모델이 개별 손실이 가장 큰 작업에 치우쳐 표현을 최적화 함\n",
    "- 다른 작업들은 손해를 입음\n",
    "- 이를 해결하기 위해 손실 값이 최종 손실에 기여하는 수준을 지정할 수 있음\n",
    "  - 손실 값의 스케일이 다를 때 유용\n",
    "- mse는 일반적으로 3~5사이의 값을 가짐, 성별 분류는 0.1\n",
    "  - 각각 0.25, 10의 가중치를 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "    loss_weight=[0.25, 1., 10.]\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='rmsprop', \n",
    "#     loss={'age' : 'mse', 'income' : 'categorical_crossentropy', 'gender' : 'binary_crossentropy'},\n",
    "#     loss_weight={\n",
    "#         'age':0.25,\n",
    "#         'income' : 1.,\n",
    "#         'gender' : 10.\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 있다고 가정하고 짠 코드\n",
    "\n",
    "# model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.4 층으로 구성된 비순환 유향 그래프(DAG)\n",
    "\n",
    "함수형 API를 사용하면 다중 입력이나 다중 출력 모델뿐만 아니라 내부 토폴로지가 복잡한 네트워크도 만들 수 있다.\n",
    "- 비순환 유향 그래프(DAG)\n",
    "- 비순환이라는 것이 중요\n",
    "  - 다시 말해 이 그래프는 원형을 띨 수 없음 -> 텐서 x가 자기 자신을 출력하는 층의 입력이 될 수 없다.\n",
    "  - 만들 수 있는 루프(순환 연결)는 순환 층의 내부에 있는 것뿐\n",
    "\n",
    "가장 유명한 2개는 인셉션 모듈과 잔차 연결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인셉션 모듈\n",
    "\n",
    "Inception은 합성곱 신경망에서 인기 있는 네트워크 구조\n",
    "- 네트워크 안의 네트워크라는 구조에 영감을 받은 구조\n",
    "- 가장 기본적인 인셉션 모듈 형태는 3~4개의 가지를 가짐\n",
    "- 네트워크가 따로따로 공간 특성과 채널 방향의 특성을 학습하도록 도움\n",
    "- 한꺼번에 학습하는 것보다 효과가 더 높음\n",
    "  - 더 복잡한 인셉션은 풀링 연산, 여러가지 합성곱 사이즈, 공간 합성곱이 없는 가지 등등\n",
    "\n",
    "![alt text](https://images.deepai.org/django-summernote/2019-06-18/2cec735b-2347-4ded-ae2b-e8a8384f7b46.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D 텐서가 입력된다고 가정\n",
    "\n",
    "from keras import layers\n",
    "\n",
    "# 모든 가지는 동일한 스트라이드(2)를 사용. 출력 크기를 동일하게 만들어 하나로 합치기 위함\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "\n",
    "# axis=-1은 현재 배열의 마지막 axis를 의미합니다.\n",
    "# http://taewan.kim/post/numpy_cheat_sheet/\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = keras.applications.inception_v3.InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잔차 연결\n",
    "\n",
    "residual connection은 Xception을 포함하여 2015년 이후 등장한 많은 네트워크 구조에 있는 그래프 형태의 네트워크 컴포넌트\n",
    "- 그래디언트 소실과 representational bottleneck을 해결\n",
    "- 10개 층 이상을 가진 모델에 잔차 연결을 추가하면 도움이 됨\n",
    "\n",
    "잔차 연결은 하위 층의 출력을 상위 층의 입력으로 사용\n",
    "- 순서대로 놓인 네트워크를 질러가는 연결이 만들어짐\n",
    "- 하위 층의 출력이 상위 층의 활성화 출력에 연결되는 것이 아니고 더해짐\n",
    "- 따라서 두 출력의 크기가 동일해야 함\n",
    "- 크기가 다르면 선형 변환을 사용하여 하위층의 활성화 출력을 목표 크기로 변환\n",
    "  - 활성화 함수를 사용하지 않는 Dense층이나 합성곱의 특성 맵이라면 활성화 함수가 없는 1 X 1 합성곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스에서 특성 맵의 크기가 같을 때 원본을 그대로 사용하는 잔차 연결을 구현한 예\n",
    "# 입력 x는 4D 텐서라고 가정\n",
    "\n",
    "from kerase import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) # x에 변환을 적용\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x]) # 원본 x를 출력 특성에 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음은 특성 맵의 크기가 다를 떄 선형 변환을 사용하여 잔차 연결을 구현한 예\n",
    "\n",
    "from kerase import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x) # x에 변환을 적용\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "# y와 크기를 맞추기 위해 1x1 합성곱을 사용하여 원본 텐서 x를 다운샘플링 함\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)\n",
    "\n",
    "y=layers.add([y, residual]) # 다운샘플링된 x를 출력 특성에 더하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.5 층 가중치 공유"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수형 API의 중요한 또 하나의 기능은 층 객체를 여러 번 재사용할 수 있다는 것\n",
    "- 층 객체를 두 번 호출하면 새로운 층 객체를 만들지 않고 각 호출에 동일한 가충치를 재사용\n",
    "- 공유 가지를 가진 모델을 만들 수 있음\n",
    "\n",
    "두 문장 사이의 의미가 비슷한지 측정하느 모델 예시\n",
    "- 두 개의 입력(비교할 두 개의 문장)\n",
    "- 0(관련 없는 문장)과 1(동일하거나 재구성) 사이의 점수 출력\n",
    "- 자연어 질의에 대한 중복 제거를 포함하여 많은 애플리케이션에서 유용하게 사용\n",
    "\n",
    "A에서 B에 대한 유사도는 B에서 A에 대한 유사도와 같다\n",
    "- 입력 시퀀스가 바뀌어도 됨\n",
    "- 각 입력 문장을 2개의 독립된 모델에서 처리하는 것보다, 하나의 LSTM 층으로 양쪽을 모두 처리하는 것이 좋음\n",
    "- 이 LSTM 층의 표현(가중치)은 두 입력에 대해 함께 학습\n",
    "- 이를 Siamese LSTM 모델(샴 LSTM) 또는 공유 LSTM 이라고 부름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "# LSTM 객체 생성\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "# 모델의 왼쪽 가지 구성, 입력은 크기가 128인 벡터의 가변 길이 시퀀스\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# 모델의 오른쪽 가지 구성, 기존 층 객체를 호출하면 가중치가 재사용됨\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# 맨 위에 분류기\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 모델 객체를 만들고 훈련, 이런 모델을 훈련하면 LSTM 층의 가중치는 양쪽 입력을 바탕으로 업데이트\n",
    "model = Model([left_output, right_output], predictions)\n",
    "model.fit([left_output, right_output], targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.6 층과 모델\n",
    "\n",
    "함수형 API 에서는 모델을 층처럼 사용할 수 있음\n",
    "- 모델을 '커다란 층'으로 생각해도 됨\n",
    "- 입력 텐서로 모델을 호출해서 출력 텐서를 얻을 수 있다는 뜻\n",
    "\n",
    "```python\n",
    "y = model(x)\n",
    "\n",
    "# 입력 텐서, 출력 텐서가 여러 개이면 텐서의 리스트로 호출\n",
    "\n",
    "y1, y2 = model([x1, x2])\n",
    "```\n",
    "\n",
    "모델 객체를 호출할 때 모델의 가중치가 재사용됨\n",
    "- 층 객체 호출 할 때와 동일한 개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "# 이미지 처리 기본 모델 = Xception Network(합성곱 기반 층만 사용)\n",
    "xception_base = application.Xception(weights=None, include_top=False)\n",
    "\n",
    "# 입력은 250 x 250 RGB\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "# 같은 비전 모델을 두 번 호출\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1.7. 정리\n",
    "- 차례대로 층을 쌓는 것 이상이 필요할 때는 Sequential API를 사용하지 않음\n",
    "- 함수형 API를 사용하여 다중 입력, 다중 출력, 복잡한 네트워크 토폴로지를 갖는 케라스 모델을 만드는 방법\n",
    "- 다른 네트워크 기지에서 같은 층이나 모델 객체를 여러 번 호출하여 가중치를 재사용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 케라스 콜백과 텐서보드를 사용한 딥러닝 모델 검사와 모니터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.1 콜백을 사용하여 모델의 훈련 과정 제어하기\n",
    "\n",
    "모델을 훈련할 때 미리 예상할 수 없는 것들이 많음\n",
    "- 최적의 에포크는 얼마인가?\n",
    "- 기타 등등....낭비가 많음\n",
    "\n",
    "더 좋은 방법은 검증 손실이 더 이상 향상되지 않을 떄 훈련을 멈추는 것\n",
    "- 케라스 콜백을 사용하여 구현 가능\n",
    "- 콜백은 모델의 fit() 메서드가 호출될 때 전달되는 객체(특정 매서드를 구현한 클래스 객체)\n",
    "- 훈련하는 동안 모델은 여러 지점에서 콜백을 호출\n",
    "- 콜백은 모델의 상태와 성능에 대한 모든 정보에 접근하고 훈련 중지, 모델 저장, 가중치 적재 또는 모델 상태 변경 등을 처리할 수 있음\n",
    "\n",
    "콜백을 사용하는 예시\n",
    "- 모델 체크포인트 저장 : 훈련하는 동안 어떤 지점에서 모델의 현재 가중치를 저장\n",
    "- 조기 종료(early stoping) : 검증 손실이 더 이상 향상되지 않을 때 훈련을 중지(물론 훈련하는 동안 얻은 가장 좋은 모델을 저장)\n",
    "- 훈련하는 동안 하이퍼파라미터 값을 동적으로 조정 : 옵티마이저의 학습률\n",
    "- 훈련과 검증 지표를 로그에 기록하거나 모델이 학습한 표현이 업데이트될 때마다 시각화 : 케라스의 진행 표시줄(progress bar)이 하나의 콜백\n",
    "\n",
    "**ModelCheckpoint와 EarlyStopping 콜백**\n",
    "\n",
    "EarlyStopping 콜백\n",
    "- 정해진 에포크 동안 모니터링 지표가 향상되지 않을 때 훈련을 중지\n",
    "- 일반적으로 이 콜백은 훈련하는 동안 모델을 계속 저장해 주는 ModelCheckpoint와 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# fit() 메서드의 callbacks 매개변수를 사용하여 콜백의 리스트를 모델로 전달. 몇 개의 콜백이라도 전달할 수 있음\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( # 성능 향상 멈추면 훈련 중지\n",
    "        monitor='val_acc', # 모델의 검증 정확도를 모니터링\n",
    "        patience=1, # 1 에포크보다 더 길게(즉 2 에포크 동안) 정확도가 향상되지 않으면 훈련이 중지\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint( # epoch 마다 현재 가중치를 저장\n",
    "        filepath='my_model.h5', # 모델 파일의 경로\n",
    "        monitor='val_loss', # val_loss가 좋아지지 않으면 모델 파일을 덮어쓰지 않는다는 뜻. 훈련하는 동안 가장 좋은 모델이 저장\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x,y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau 콜백\n",
    "- 검증 손실이 향상되지 않을 때 학습률을 작게 할 수 있음\n",
    "- 손실 곡선이 평탄할 때 학습률을 작게 하거나 크게 하면 훈련 도중 지역(local) 최솟값에서 효과적으로 빠져나올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', # 모델의 검증 손실을 모니터링\n",
    "        factor=0.1, # 콜백이 호출될 때 학습률을 10배로 줄임\n",
    "        patience=10, # 검증 손실이 10 에포크 동안 좋아지지 않으면 콜백이 호출됨\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    x,y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자신만의 콜백 만들기도 가능하다 - 책 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2.2 텐서보드 소개 : 텐서플로우 시각화 프레임워크\n",
    "\n",
    "설명 작성 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 100, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 94, 32)            28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 18, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 12, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 2000\n",
    "max_len = 100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory_path = os.getcwd()\n",
    "log_directory_path = current_directory_path + os.sep + 'my_log_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 7s 333us/sample - loss: 2.0056 - acc: 0.6403 - val_loss: 0.4883 - val_acc: 0.7772\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.4808 - acc: 0.8123 - val_loss: 0.5469 - val_acc: 0.7868\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 6s 319us/sample - loss: 0.4305 - acc: 0.8437 - val_loss: 0.4818 - val_acc: 0.8082\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 6s 303us/sample - loss: 0.3609 - acc: 0.8741 - val_loss: 0.8200 - val_acc: 0.7832\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 7s 333us/sample - loss: 0.3217 - acc: 0.8949 - val_loss: 0.6512 - val_acc: 0.8110\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 6s 299us/sample - loss: 0.2785 - acc: 0.9232 - val_loss: 0.7543 - val_acc: 0.8124\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 6s 295us/sample - loss: 0.2244 - acc: 0.9444 - val_loss: 0.8068 - val_acc: 0.8114\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 6s 296us/sample - loss: 0.1645 - acc: 0.9670 - val_loss: 1.0190 - val_acc: 0.8032\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 6s 307us/sample - loss: 0.1322 - acc: 0.9809 - val_loss: 1.4699 - val_acc: 0.7878\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.1082 - acc: 0.9879 - val_loss: 1.2694 - val_acc: 0.7970\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.0954 - acc: 0.9900 - val_loss: 1.3390 - val_acc: 0.8068\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 0.0918 - acc: 0.9907 - val_loss: 1.3675 - val_acc: 0.8034\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 6s 304us/sample - loss: 0.0905 - acc: 0.9905 - val_loss: 1.6193 - val_acc: 0.7900\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 6s 301us/sample - loss: 0.0892 - acc: 0.9905 - val_loss: 1.5528 - val_acc: 0.8038\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.0843 - acc: 0.9923 - val_loss: 1.6485 - val_acc: 0.8070\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 6s 300us/sample - loss: 0.0911 - acc: 0.9904 - val_loss: 1.6542 - val_acc: 0.8062\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 6s 305us/sample - loss: 0.0848 - acc: 0.9922 - val_loss: 1.6704 - val_acc: 0.8030\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 6s 302us/sample - loss: 0.0815 - acc: 0.9930 - val_loss: 1.7985 - val_acc: 0.8030\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 6s 310us/sample - loss: 0.0910 - acc: 0.9916 - val_loss: 1.7960 - val_acc: 0.8022\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 6s 312us/sample - loss: 0.0802 - acc: 0.9930 - val_loss: 1.8610 - val_acc: 0.8068\n"
     ]
    }
   ],
   "source": [
    "callbacks_value = [\n",
    "    callbacks.TensorBoard(\n",
    "        log_dir=log_directory_path, # 로그 파일이 기록될 위치\n",
    "        histogram_freq=1, # 1 에포크마다 활성화 출력의 히스토그램을 기록\n",
    "        embeddings_freq=1, # 1 에포크마다 임베딩 데이터를 기록\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "history=model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks_value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 모델의 성능을 최대로 끌어올리기\n",
    "\n",
    "#### 7.3.1 고급 구조 패턴\n",
    "\n",
    "**배치 정규화**\n",
    "\n",
    "정규화는 머신 러닝 모델에 주입되는 샘플들을 균일하게 만드는 광범위한 방법\n",
    "- (데이터 - 평균) / 표준편차, 분산 1\n",
    "\n",
    "\n",
    "```python\n",
    "normalized_data = (data - np.mean(data, axis=...)) / np.std(data, axis=...)\n",
    "```\n",
    "\n",
    "이전에는 모델에 데이터를 주입하기 전에 정규화 했음\n",
    "- 하지만 데이터 정규화는 네트워크에서 일어나는 모든 변환 후에도 고려되어야 함\n",
    "- 쉽게 말해 입력 할 때 들어가는 데이터가 정규화 되어 있더라도, 출력 되는 데이터가 정규화 되어 있다는 보장 못 함\n",
    "\n",
    "\n",
    "Batch normalization\n",
    "- 훈련하는 동안 평균과 분산이 바뀌더라도 이에 적응하여 데이터를 정규화 함\n",
    "- 훈련 과정에 사용된 배치 데이터의 평균과 분산에 대한 지수 이동 평균을 내부에 유지\n",
    "- 배치 정규화의 주요 효과는 잔차 연결과 매우 흡사하게 gradient의 전파를 도와주는 것\n",
    "- 결국 더 깊은 네트워크를 구성할 수 있음\n",
    "- 매우 깊은 네트워크라면 여러 개의 BatchNormalization 층을 포함해야 훈련할 수 있음\n",
    "- BatchNormalization 층은 일반적으로 합성곱이나 완전 연결 층 다음에 사용\n",
    "\n",
    "```python\n",
    "# Conv2D 층 다음에\n",
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "\n",
    "# Dense 층 다음에\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())\n",
    "```\n",
    "\n",
    "BatchNormalization 클래스에는 정규화할 특서 축을 지정하는 axis 매개변수가 있음\n",
    "- 매개변수 기본값은 입력 텐서의 마지막 축을 나타내는 -1\n",
    "> axis: Integer, the axis that should be normalized\n",
    "        (typically the features axis).\n",
    "        For instance, after a `Conv2D` layer with\n",
    "        `data_format=\"channels_first\"`,\n",
    "        set `axis=1` in `BatchNormalization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgamma_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ones'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmoving_mean_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmoving_variance_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ones'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgamma_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbeta_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgamma_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Batch normalization layer (Ioffe and Szegedy, 2014).\n",
       "\n",
       "Normalize the activations of the previous layer at each batch,\n",
       "i.e. applies a transformation that maintains the mean activation\n",
       "close to 0 and the activation standard deviation close to 1.\n",
       "\n",
       "# Arguments\n",
       "    axis: Integer, the axis that should be normalized\n",
       "        (typically the features axis).\n",
       "        For instance, after a `Conv2D` layer with\n",
       "        `data_format=\"channels_first\"`,\n",
       "        set `axis=1` in `BatchNormalization`.\n",
       "    momentum: Momentum for the moving mean and the moving variance.\n",
       "    epsilon: Small float added to variance to avoid dividing by zero.\n",
       "    center: If True, add offset of `beta` to normalized tensor.\n",
       "        If False, `beta` is ignored.\n",
       "    scale: If True, multiply by `gamma`.\n",
       "        If False, `gamma` is not used.\n",
       "        When the next layer is linear (also e.g. `nn.relu`),\n",
       "        this can be disabled since the scaling\n",
       "        will be done by the next layer.\n",
       "    beta_initializer: Initializer for the beta weight.\n",
       "    gamma_initializer: Initializer for the gamma weight.\n",
       "    moving_mean_initializer: Initializer for the moving mean.\n",
       "    moving_variance_initializer: Initializer for the moving variance.\n",
       "    beta_regularizer: Optional regularizer for the beta weight.\n",
       "    gamma_regularizer: Optional regularizer for the gamma weight.\n",
       "    beta_constraint: Optional constraint for the beta weight.\n",
       "    gamma_constraint: Optional constraint for the gamma weight.\n",
       "\n",
       "# Input shape\n",
       "    Arbitrary. Use the keyword argument `input_shape`\n",
       "    (tuple of integers, does not include the samples axis)\n",
       "    when using this layer as the first layer in a model.\n",
       "\n",
       "# Output shape\n",
       "    Same shape as input.\n",
       "\n",
       "# References\n",
       "    - [Batch Normalization: Accelerating Deep Network Training by\n",
       "       Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/keras/layers/normalization.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras.layers.BatchNormalization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**깊이별 분리 합성곱**\n",
    "\n",
    "Conv2D를 대체하면서 더 가볍고 더 빨라 모델의 성능을 높일 수 있는 층이 있...?\n",
    "- 깊이별 분리 합성곱(depthwise separable convolution) - SeparableConv2D\n",
    "- 이 층은 입력 채널별로 따로따로 공간 방향의 합성곱을 수행 -> 그 후 점별 합성곱(1 x 1 합성곱)을 통해 출력 채널을 합침\n",
    "- 이는 공간 특성의 학습과 채널 방향 특성의 학습을 분리하는 효과를 냄\n",
    "- 입력에서 공간상 위치는 상관관계가 크지만 채널별로는 매우 독립적이라고 가정한다면 타당\n",
    "- 이 방법은 모델 파라미터와 연산의 수를 크게 줄여 주기 때문에 작고 더 빠른 모델을 만듬\n",
    "\n",
    "이 장점은 제한된 데이터로 작은 모델을 처음부터 훈련시킬 때 특히 더 중요\n",
    "- 작은 데이터셋에서 이미지 분류 문제(소프트맥스 분류)를 위한 가벼운 깊이별 분리 컨브넷 예시...아래 보자\n",
    "\n",
    "```python\n",
    "height, width, channels, num_classes = 64, 64, 3, 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(\n",
    "    32, 3, activation='relu', input_shape=(height, width, channels,)\n",
    "))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.2 하이퍼파라미터 최적화\n",
    "\n",
    "하루종일 하이퍼파라미터를 수정하는 것은 사람이 할 짓이 아니다. -> 기계에 위임하는 것이 더 낫다\n",
    "\n",
    "최적화 과정\n",
    "1. 일련의 하이퍼파라미터를 (자동으로) 선택\n",
    "2. 선택된 하이퍼파라미터로 모델을 만듬\n",
    "3. 훈련 데이터에 학습하고 검증 데이터에서 최종 성능을 측정\n",
    "4. 다음으로 시도할 하이퍼파라미터를 (자동으로) 선택\n",
    "5. 이 과정을 반복\n",
    "6. 마지막으로 테스트 데이터에서 성능을 측정\n",
    "\n",
    "여러 가지 기법을 사용할 수 있음\n",
    "- 베이지안 최적화(bayesian optimization)\n",
    "- 유전 알고리즘(genetic algorithms)\n",
    "- 간단한 랜덤 탐색(random search)\n",
    "- 라이브러리 : https://github.com/hyperopt/hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
