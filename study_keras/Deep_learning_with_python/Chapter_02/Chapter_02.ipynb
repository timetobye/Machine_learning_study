{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ch2. 신경망의 수학적 구성 요소\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 신경망과의 첫 만남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import models, layers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data from keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**activation 설정시**\n",
    "- activation 값을 설정 할 때 마지막 layer에서 softmax로 했더니 에러가 남\n",
    "- 해결책\n",
    "  - https://keras.io/activations/\n",
    "  - https://github.com/keras-team/keras/issues/9621#issuecomment-394664543\n",
    "- 또는 tensorflow에서 바로 가져와도 된다.\n",
    "\n",
    "```python\n",
    "from keras import backend as K\n",
    "model.add(Dense(64, activation=K.tanh))\n",
    "\n",
    "from keras import backend as K\n",
    "model.add(Lambda(lambda x: K.tf.nn.softmax(x)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 핵심 구성 요소는 일종의 데이터 처리 필터라고 할 수 있는 layer(층)이다.\n",
    "- 어떤 데이터가 들어가면 더 유용한 형태로 출력됨\n",
    "- 그 다음 더 의미가 있는 representation을 입력된 데이터로부터 출력함\n",
    "\n",
    "\n",
    "위의 예제에서는 fully connected된(완전 연결) 신경망 층인 Dense 층 2개가 속함\n",
    "- 마지막 층은 10개의 확률 점수가 들어 있는 배열(모두 더하면 1입니다)을 반환하는 소프트맥스 층입니다. 각 점수는 현재 숫자 이미지가 10개의 숫자 클래스 중 하나에 속할 확률입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망이 훈련 준비를 마치기 위해서 컴파일 단계에 포함될 세 가지가 더 필요합니다:\n",
    "\n",
    "- loss function(손실 함수) : 훈련 데이터에서 신경망의 성능을 측정하는 방법으로 네트워크가 옳은 방향으로 학습될 수 있도록 도와 줍니다.\n",
    "- optimizer(옵티마이저): 입력된 데이터와 손실 함수를 기반으로 네트워크를 업데이트하는 메커니즘입니다.\n",
    "- metrics(훈련과 테스트 과정을 모니터링할 지표) : 여기에서는 정확도(정확히 분류된 이미지의 비율)만 고려하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 시작하기 전에 데이터를 네트워크에 맞는 크기로 바꾸고 모든 값을 0과 1 사이로 스케일을 조정합니다. \n",
    "- 예를 들어, 앞서 우리의 훈련 이미지는 [0, 255] 사이의 값인 uint8 타입의 (60000, 28, 28) 크기를 가진 배열로 저장되어 있습니다.\n",
    "- 이 데이터를 0과 1 사이의 값을 가지는 float32 타입의 (60000, 28 * 28) 크기의 배열로 바꿉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블을 범주형으로 인코딩\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2559 - acc: 0.9264\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.1021 - acc: 0.9702\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0678 - acc: 0.9798\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0495 - acc: 0.9853\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0372 - acc: 0.9891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120ce5cf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 45us/step\n",
      "test_acc: 0.97\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 신경망을 위한 데이터 표현\n",
    "\n",
    "모든 머신 러닝 시스템은 일반적으로 텐서를 기본 데이터 구조로 사용\n",
    "\n",
    "**텐서는 무엇일까?**\n",
    "- 데이터를 위한 컨테이너 개념\n",
    "- 거의 항상 수치형 데이터를 다룸\n",
    "- 텐서는 임의의 차원 개수를 가지는 행렬의 일반화된 모습\n",
    "- 텐서에서는 dimension을 종종 축(axis)라고 부르기도 함\n",
    "\n",
    "텐서에 대한 아주 좋은 설명\n",
    "- https://www.youtube.com/watch?v=m0qwxNA7IzI\n",
    "- 허민석 님 짱!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "허민석 님의 tensor 강의 내역 정리\n",
    "\n",
    "|rank|type    |example                                     |설명                                                          |\n",
    "|----|--------|--------------------------------------------|------------------------------------------------------------|\n",
    "|0   |scalar  |[1]                                         |숫자 하나만 가지고 있는 것                                             |\n",
    "|1   |vector  |[1, 1]                                      |숫자를 여러개 가지고 있는 것 = vector                                   |\n",
    "|2   |matrix  |[ [1, 1] , [1, 1] ]                         |vector를 여러개 가지고 있는 tensor = matrix rank 1 tensor를 여러개 가지고 있다|\n",
    "|3   |3 tensor|[ [ [1, 1] , [1, 1] ], [ [1, 1] , [1, 1] ] ]|rank 2 tensor를 여러개 가지고 있다                                   |\n",
    "|N   |N tensor|                                            |                                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 스칼라(0D 텐서)\n",
    "\n",
    "하나의 숫자만 담고 있는 텐서를 스칼라(scalar)라고 부름\n",
    "- numpy에서는 float32, float64 타입의 숫자가 스칼라 텐서임\n",
    "- ndim 속성을 사용하면 넘파이 배열의 축 개수를 확인 할 수 있음\n",
    "- 스칼라 텐서의 축 개수는 0이다(ndim==0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "x = np.array(12)\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 벡터(1D 텐서)\n",
    "\n",
    "숫자의 배열을 벡터(vector) 또는 1D 텐서라고 부름\n",
    "- 딱 하나의 축을 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12  3  6 14  7]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14, 7])\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 벡터는 5개의 원소를 가지고 있으므로 5차원 벡터라고 부름\n",
    "- 5D 벡터와 5D 텐서를 혼동하면 안 됨\n",
    "- 5D **벡터**는 하나의 축을 따라 5개의 차원을 가진 것\n",
    "- 5D **텐서**는 5개의 축을 가진 것\n",
    "  - 텐서의 각 축을 따라 여러 개의 차원을 가진 벡터가 놓일 수 있다.\n",
    "\n",
    "- 차원수는(dimensionality)는 특정 축을 따라 놓인 원소의 개수(5d-vector)이거나 텐서의 축 개수(5d-tensor)를 의미하므로 혼동하기 쉬움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 78  2 34  0]\n",
      " [ 6 79  3 35  1]\n",
      " [ 7 80  4 37  2]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 37, 2]])\n",
    "\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 축에 놓여 있는 원소를 행이라 부른다.\n",
    "- 두 번째 축에 놓여 있는 원소를 열이라 부른다.\n",
    "- x의 첫 번째 행은 [5, 78, 2, 34, 0], 첫 번째 열은 [5,6,7] 이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 3D 텐서와 고차원 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 37, 2]],\n",
    "             [[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 37, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 37, 2]]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 37  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 37  2]]\n",
      "\n",
      " [[ 5 78  2 34  0]\n",
      "  [ 6 79  3 35  1]\n",
      "  [ 7 80  4 37  2]]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 핵심 속성\n",
    "텐서는 3개의 핵심 속성으로 정의한다.\n",
    "\n",
    "- **축의 개수(랭크)**\n",
    "  - 예를 들어 3D 텐서에는 3개의 축이 있고, 행렬에는 2개의 축이 있다.\n",
    "  - numpy의 ndim으로 확인 가능\n",
    "- **크기(shape)**\n",
    "  - 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 tuple\n",
    "  - 예를 들어 앞에 나온 행렬의 크기는 (3,5)이고 3D 텐서의 크기는 (3,3,5)이다.\n",
    "  - 벡터의 크기는 (5,) 처럼 1개의 원소로 이루어진 튜플\n",
    "  - 배열 스칼라는 ()처럼 크기가 없다.\n",
    "- **데이터 타입**\n",
    "  - 텐서에 포함된 데이터의 타입\n",
    "  - 예를 들면 텐서의 타입은 float32, float64, uint8 등이 될 수 있다.\n",
    "  - 텐서는 사전에 할당되어 연속된 메모리에 저장되어야 하므로 numpy 배열은 가변 문자열을 지원하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_images.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# 8비트 정수형 3D 텐서\n",
    "# 좀 더 정확하게는 28 * 28 크기의 정수 행렬 6만 개가 있는 배열\n",
    "# 각 행렬은 하나의 흑백 이미지, 각 원소는 0에서 255 사이의 값을 가짐\n",
    "\n",
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images.dtype?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 numpy로 텐서 조작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[10:100, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[10:100, 0:28, 0:28].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.7 배치 데이터\n",
    "\n",
    "일반적으로 딥러닝에서 사용하는 모든 데이터 텐서의 첫 번째 축은 샘플 축(sample axis)이다.\n",
    "- 딥러닝 모델은 한 번에 전체 데이터셋을 처리 하지 않음\n",
    "- 그 대신 데이터를 작은 배치(batch)로 나눔\n",
    "- 구체적으로 MNIST 숫자 데이터에서 크기가 128인 배치 하나는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_one = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_two = train_images[128:256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_n = train_images[128 * n : 128(n * 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이런 배치 데이터를 다룰 때는 첫 번째 축을 배치 축 또는 배치 차원이라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.8 텐서의 실제 사례\n",
    "- 벡터 데이터 : (samples, features), 2D\n",
    "- 시계열 데이터, sequence 데이터 : (samples, timesteps ,features), 3D\n",
    "- 이미지 데이터 : (samples, height, width, channels), (samples, channels, height, width), 4D\n",
    "- 동영상 데이터 : (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width), 5D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.9 벡터 데이터 ~ 2.2.12 비디오 데이터\n",
    "- 자세한 내용은 책 참조\n",
    "\n",
    "\n",
    "흑백 이지미의 경우 컬러 채널의 차원 크기는 1\n",
    "- 256 * 256 크기의 흑백 이미지에 대한 128개의 배치는 (128, 256, 256, 1)\n",
    "\n",
    "이미지 텐서 크기를 지정하는 방법은 두 가지\n",
    "- channel_last\n",
    "  - 텐서플로우에서 사용\n",
    "- channel_first\n",
    "  - 씨애노에서 사용\n",
    "- keras는 둘 다 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 신경망의 톱니바퀴 : 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "keras.layers.Dense(512, activation='relu')\n",
    "```\n",
    "\n",
    "```bash\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "\n",
    "- 정리하면 3개의 텐서 연산이 위 수식에 있다.\n",
    "- 입력 텐서와 텐서 W 사이이 dot product\n",
    "- 그 결과를 b와 덧셈\n",
    "- 마지막으로 relu 연산 ( relu(x) 는 max(x, 0)임 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 원소별 연산\n",
    "- relu 함수와 덧셈은 원소별 연산. 자세한 코드는 책 잠조\n",
    "\n",
    "\n",
    "```python\n",
    "z = x + y # 원소별 덧셈\n",
    "\n",
    "z = np.maximum(z, 0.) # 원소별 렐루 함수\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 브로드캐스팅\n",
    "\n",
    "크기가 다른 두 텐서가 더해질 때 어떻게 될까?\n",
    "- 작은 텐서가 큰 텐서의 크기에 맞추어 브로드캐스팅(broadcasting) 됨\n",
    "- 브로드캐스팅은 두 단계로 이루어짐\n",
    "  - 큰 텐서의 ndim에 맞도록 작은 텐서의(브로드캐스팅 축이라고 부르는) 축이 추가됨\n",
    "  - 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Produce an object that mimics broadcasting.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "in1, in2, ... : array_like\n",
       "    Input parameters.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "b : broadcast object\n",
       "    Broadcast the input parameters against one another, and\n",
       "    return an object that encapsulates the result.\n",
       "    Amongst others, it has ``shape`` and ``nd`` properties, and\n",
       "    may be used as an iterator.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "broadcast_arrays\n",
       "broadcast_to\n",
       "\n",
       "Examples\n",
       "--------\n",
       "\n",
       "Manually adding two vectors, using broadcasting:\n",
       "\n",
       ">>> x = np.array([[1], [2], [3]])\n",
       ">>> y = np.array([4, 5, 6])\n",
       ">>> b = np.broadcast(x, y)\n",
       "\n",
       ">>> out = np.empty(b.shape)\n",
       ">>> out.flat = [u+v for (u,v) in b]\n",
       ">>> out\n",
       "array([[5.,  6.,  7.],\n",
       "       [6.,  7.,  8.],\n",
       "       [7.,  8.,  9.]])\n",
       "\n",
       "Compare against built-in broadcasting:\n",
       "\n",
       ">>> x + y\n",
       "array([[5, 6, 7],\n",
       "       [6, 7, 8],\n",
       "       [7, 8, 9]])\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/numpy/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.broadcast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "<numpy.broadcast object at 0x5577eba4a640>\n"
     ]
    }
   ],
   "source": [
    "# example broadcast\n",
    "\n",
    "x = np.array([[1], [2], [3]])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "print(x.ndim, y.ndim)\n",
    "\n",
    "b = np.broadcast(x, y)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 6., 7.],\n",
       "       [6., 7., 8.],\n",
       "       [7., 8., 9.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.empty(b.shape)\n",
    "out.flat = [u+v for (u,v) in b]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1), (3,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6, 7],\n",
       "       [6, 7, 8],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 텐서 점곱\n",
    "\n",
    "- 텐서 곱셉(tensor product)이라고도 부르는 점곱 연산(dot operation)은 가장 널리 사용되고 유용한 텐서 연산\n",
    "- 원소별 연산과 반대로 입력 텐서의 원소들을 결합 시킴\n",
    "\n",
    "```python3\n",
    "import numpy as np\n",
    "\n",
    "z = np.dot(x, y)\n",
    "z = x * y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 텐서 크기 변환\n",
    "\n",
    "tensor reshaping\n",
    "\n",
    "```python3\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "```\n",
    "\n",
    "텐서의 크기를 변환한다는 것은 특정 크기에 맞게 열과 행을 재배열한다는 뜻\n",
    "- 당연히 크기가 변환된 텐서는 원래 텐서와 원소 개수가 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 2.]\n",
      " [3. 4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape((2, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자주 사용하는 특별한 크기 변환은 전치(transposition)\n",
    "- 행렬의 전치는 행과 열을 바꾸는 것을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 텐서 연산의 기하학적 해석\n",
    "- 책 참조\n",
    "\n",
    "#### 2.3.6 딥러닝의 기하학적 해석\n",
    "- 책 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 신경망의 엔진 : optimazer based gradient\n",
    "\n",
    "```bash\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "\n",
    "위 식에서 텐서 W와 b는 층의 속성처럼 볼 수 있다.\n",
    "- 가중치(weight) 또는 훈련되는 파라미터(trainable parameter)라고 볼 수 있다.\n",
    "- 또는 각각 kernel과 bias라고 부르기도 한다.\n",
    "- 이런 가중치에는 훈련 데이터를 신경망에 노출시켜서 학습된 정보가 담겨 있다.\n",
    "\n",
    "초기 가중치 행렬이 작은 난수로 채워져 있음\n",
    "- 처음에는 의미 없는 표현이지만, 피드백 신호에 기초하여 가중치가 점진적으로 조정됨\n",
    "- 이런 것을 우리는 training이라고 부름\n",
    "- 반복...\n",
    "\n",
    "\n",
    "단계\n",
    "1. 훈련 샘플 x와 이에 상응하는 타깃 y의 배치를 추출\n",
    "2. x를 사용하여 forward pass, 예측 y_pred를 구함\n",
    "3. y_pred와 y의 차이를 측정하여 이 배치에 대한 네트워크의 loss를 계산\n",
    "4. 배치에 대한 손실이 조금 감소되도록 네트워크의 모든 가중치를 업데이트\n",
    "\n",
    "\n",
    "**연산 과정에서 신경망에 사용된 모든 연산이 미분 가능(differentiable)하다는 장점을 사용하여 네트워크 가중치에 대한 손실의 gradient를 계산하는 것이 훨씬 더 좋은 방법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 텐서 연산의 변화율 : gradient\n",
    "\n",
    "gradient는 텐서 연산의 변화율\n",
    "- 다차원 입력, 즉 텐서를 입력으로 받는 함수에 변화율 개념을 확장 시킨 것\n",
    "- 자세한 건 책 잠조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 확률적 경사 하강법\n",
    "\n",
    "Gradient Descent(경사 하강법)\n",
    "- 미분 가능한 함수가 주어지면 이론적으로 이 함수의 최솟값을 해석적으로 구할 수 있다.\n",
    "- 함수의 최솟값은 변화율이 0인 지점\n",
    "- 신경망에 적용하면 가장 작은 손실 함수의 값을 만드는 가중치의 조합을 해석적으로 찾는 것을 의미함\n",
    "- gradient(f)(W) = 0을 풀면 됨(gradient(f)는 변화율 함수)\n",
    "\n",
    "\n",
    "1. 훈련 샘플 배치 x와 이에 상응하는 타깃 y를 추출\n",
    "2. x로 네트워크를 실행하고 예측 y_pred를 구함\n",
    "3. 이 배치에서 y_pred와 y 사이의 오차를 측정하여 네트워크의 손실을 계산\n",
    "4. 네트워크의 파라미터에 대한 손실 함수의 gradient를 계산(backward pass...)\n",
    "5. gradient의 반대 방향으로 파라미터를 조금 이동 시킴. 예를 들어 W -= step * gradient 하면 배치에 대한 손실이 조금 감소할 것\n",
    "\n",
    "> 위의 과정을 mini-batch stochastic gradient descent라고 함(미니 배치 확률적 경사 하강법), 속칭 SGD\n",
    "\n",
    "> 확률적이라는 각 배치 데이터가 무작위로 선택한다는 의미\n",
    "\n",
    "![alt text](https://www.jeremyjordan.me/content/images/2018/02/Screen-Shot-2018-02-24-at-11.47.09-AM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate를 적절히 고르는 것이 중요\n",
    "- 이 값이 너무 작으면 곡선을 따라 내려가는 데 너무 많은 반복이 필요하고 local minimum에 갇힐 수 있음\n",
    "- 너무 크면 loss function에서 완전히 임의의 위치로 이동시킬 수 있음\n",
    "\n",
    "여러 가지 방법이 있다.\n",
    "- 반복마다 하나의 샘플과 하나의 타깃을 뽑는 것\n",
    "- 가용한 모든 데이터를 사용하여 반복 실행(이를 SGD라고 함)\n",
    "  - 단 비용이 많이 듬\n",
    "- 적절하게 잘 사용하자\n",
    "\n",
    "또다른 바업ㅂ으로는 현재 gradient 값만 보지 않고 이전에 업데이트된 가중치를 여러 가지 다른 방식으로 고려하는 SGD의 변화된 방식이 있음\n",
    "- 예를 들면 momentum을 사용한 SGD, Adagrad, RMSProp 등\n",
    "- 이런 방법들은 모두 optimization method 또는 옵티마이저 라고 부름\n",
    "- momentum은 SGD에 있는 2개의 문제점인 수렴 속도와 지역 최솟값을 해결함\n",
    "\n",
    "![alt text](https://www.researchgate.net/profile/Marc_Sevaux/publication/258159898/figure/fig1/AS:612163295141889@1522962511560/Minimum-local-et-global.png)\n",
    "\n",
    "\n",
    "물리학에서 영감을 얻은 모멘텀....\n",
    "- loss function 위로 작은 공을 굴리는 것으로 생각하면 이해가 쉬움\n",
    "- 모멘텀이 충분하다면 공이 골짜기에 갇히지 않고 global minumum에 도달할 것\n",
    "- 현재 기울기 뿐만 아니라, 과거 기울기도 고려하여 움직이기 때문이다.\n",
    "\n",
    "\n",
    "```python\n",
    "# example code of momentum\n",
    "\n",
    "past_velocity = 0\n",
    "momentum = 0.1\n",
    "while loss > 0.01:\n",
    "    w, loss, gradient = get_current_parameters()\n",
    "    velocity = momentum * past_velocity - learning_rate * gradient\n",
    "    w = w + momentum * velocity - learning_rate * gradient\n",
    "    past_velocity = velocity\n",
    "    update_parameter(w)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.4 변화율 연결 : 역전파 알고리즘\n",
    "- 책 참조\n",
    "- 연쇄 미분 기억하면 됨\n",
    "- 수식 보다는 gradient와 optimizer에 대해 잘 이해하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 첫 번째 예제 다시 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28* 28))\n",
    "train_images = train_images.astype('float32') /255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28* 28))\n",
    "test_images = test_images.astype('float32') /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28, )))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_crossentropy은 loss function이다.\n",
    "# 가중치 텐서를 학습하기 위한 피드백 신호로 사용되며, 훈련하는 동안 최소화 된다.\n",
    "# 미니 배치 SGD를 통해 손실이 감소됨\n",
    "# gradient descent 적용하는 구체적인 방식은 첫 번째 매개변수로 전달된 rmsprop 옵티마이저에 의해 결정됨\n",
    "\n",
    "network.compile(\n",
    "    loss='categorical_crossentropy', # loss function\n",
    "    optimizer='rmsprop', #\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.2520 - accuracy: 0.9272\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1028 - accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0684 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0488 - accuracy: 0.9858\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0373 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa9994e1048>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8906164e-08, 3.6788245e-10, 8.2435565e-07, ..., 9.9988306e-01,\n",
       "        3.7492121e-08, 3.6396308e-05],\n",
       "       [2.2148060e-12, 2.3510593e-06, 9.9999726e-01, ..., 1.9944214e-16,\n",
       "        1.2518305e-07, 6.8040026e-17],\n",
       "       [1.1733110e-08, 9.9978811e-01, 2.6602076e-05, ..., 1.2279156e-04,\n",
       "        4.0634954e-05, 3.3867431e-07],\n",
       "       ...,\n",
       "       [1.3194150e-13, 6.4476940e-10, 1.1278363e-10, ..., 7.0820561e-06,\n",
       "        4.5319254e-07, 6.4053544e-04],\n",
       "       [6.6864139e-11, 5.6971896e-11, 3.4966024e-13, ..., 2.6602515e-10,\n",
       "        2.1423295e-06, 5.2268259e-12],\n",
       "       [2.0387943e-11, 1.4202460e-15, 1.7460650e-09, ..., 9.4304976e-17,\n",
       "        2.0928981e-12, 9.8973150e-14]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 요약\n",
    "\n",
    "- 학습(learning)은 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화 하는 모델 파라미터의 조합을 찾는 것을 의미\n",
    "- 데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습 진행됨\n",
    "- 전체 학습 과정은 신경망이 미분 가능한 텐서 연산으로 연결되어 있기 때문에 가능. 미분의 연쇄 법칙을 잊지 말자(고2 때 나옴...)\n",
    "- loss 와 optimizer는 짱짱 중요함, 네트워크에 데이터를 입력하기 전에 정의되어야 함\n",
    "- loss는 훈련하는 동안 최소화해야 할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용\n",
    "- optimizer는 손실에 대한 gradient가 parameter를 업데이트하는 정확한 방식을 정의\n",
    "  - 예를 들어 RMSProp, SGD 등"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
