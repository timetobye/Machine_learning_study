{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 CNN 원리\n",
    "--------\n",
    "\n",
    "- CNN의 원리\n",
    "- 필기체를 분류하는 CNN 구현\n",
    "- 컬러 이미지를 분류하는 CNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 CNN의 원리\n",
    "\n",
    "CNN은 convolution filter(합성곱 필터)를 이용하여 신경망 동작을 수행\n",
    "- 여러 작은 필터가 이미지 위를 돌아다니면서 특징점들을 찾아 그 합성곱 결과를 다음 계층으로 보냄\n",
    "- 적은 수의 가중치로 이미지 처리를 효율적으로 할 수 있음\n",
    "\n",
    "CNN은 입력 부근 계층들을 합성곱 계층으로 구성하고, 출력 부근 계층들을 fully connectd layer로 구성\n",
    "- CNN을 구성하는 계층 중에 합성곱 계층들은 특징점을 효과적으로 찾는 데 활용되고, fully connectd layer들은 찾은 특정점을 기반으로 이미지를 분류하는 데 주로 활용\n",
    "\n",
    "CNN은 2차원이나 그 이상 차원의 데이터 처리에 적합\n",
    "\n",
    "![alt text](https://e2e.ti.com/cfs-file/__key/communityserver-blogs-components-weblogfiles/00-00-00-08-94/TIDL-CNN.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN vs DNN\n",
    "\n",
    "- DNN은 이미지를 1차원 벡터로 변환하여 전 계층이 1차원 방식으로 신호를 처리하기 때문에 2차원 특성을 처리하기에는 한계가 있음\n",
    "- CNN은 2차원 convolution(합성곱)으로 각 노드를 처리하기 때문에 이미지에 더 적합\n",
    "  - CNN은 이미지의 높이와 넓이를 생각하면서 2차원 처리를 수행\n",
    "  - 컬러 이미지를 다룰 경우 컬러에 대한 계층은 깊이(depth)라는 별도의 차원으로 관리\n",
    "  - Convoluton layer가 끝나면 Maxpooling layer를 이용해 각 지역별로 최대값을 찾아줌\n",
    "  - 이렇게 하면 특징점 위치가 약간씩 달라져도 딥러닝을 제대로 수행 가능해지게 됨\n",
    "  \n",
    "![alt text](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 필기체를 분류하는 CNN 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 분류 CNN 모델링\n",
    "\n",
    "convolution layer와 fully connected layer를 결합하여 구성된 분류 CNN 모델링\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN에 사용하는 layer와 내부 패키지\n",
    "\n",
    "- Dense\n",
    "- Dropout\n",
    "- Conv2D : 2차원 합성곱을 계산하는 클래스\n",
    "- MaxPooling2D : 2차원 맥스풀링을 계산하는 클래스\n",
    "- Flatten : 다차원의 입력을 1차원의 입력으로 변환하는 클래스\n",
    "\n",
    "\n",
    "CNN에서는 filter를 kernerl이라고 부르기도 한다.\n",
    "- 아래 layers.Conv2D의 docs를 보면 fiters, kernel_size 이렇게 써있는데...\n",
    "- 이해하면 결국 filter size를 의미하는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 엔진 직접 제어 가능\n",
    "\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "2D convolution layer (e.g. spatial convolution over images).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input to produce a tensor of\n",
       "outputs. If `use_bias` is True,\n",
       "a bias vector is created and added to the outputs. Finally, if\n",
       "`activation` is not `None`, it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide the keyword argument `input_shape`\n",
       "(tuple of integers, does not include the sample axis),\n",
       "e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
       "in `data_format=\"channels_last\"`.\n",
       "\n",
       "# Arguments\n",
       "    filters: Integer, the dimensionality of the output space\n",
       "        (i.e. the number output of filters in the convolution).\n",
       "    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
       "        width and height of the 2D convolution window.\n",
       "        Can be a single integer to specify the same value for\n",
       "        all spatial dimensions.\n",
       "    strides: An integer or tuple/list of 2 integers,\n",
       "        specifying the strides of the convolution along the width and height.\n",
       "        Can be a single integer to specify the same value for\n",
       "        all spatial dimensions.\n",
       "        Specifying any stride value != 1 is incompatible with specifying\n",
       "        any `dilation_rate` value != 1.\n",
       "    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "    data_format: A string,\n",
       "        one of `channels_last` (default) or `channels_first`.\n",
       "        The ordering of the dimensions in the inputs.\n",
       "        `channels_last` corresponds to inputs with shape\n",
       "        `(batch, height, width, channels)` while `channels_first`\n",
       "        corresponds to inputs with shape\n",
       "        `(batch, channels, height, width)`.\n",
       "        It defaults to the `image_data_format` value found in your\n",
       "        Keras config file at `~/.keras/keras.json`.\n",
       "        If you never set it, then it will be \"channels_last\".\n",
       "    dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
       "        the dilation rate to use for dilated convolution.\n",
       "        Can be a single integer to specify the same value for\n",
       "        all spatial dimensions.\n",
       "        Currently, specifying any `dilation_rate` value != 1 is\n",
       "        incompatible with specifying any stride value != 1.\n",
       "    activation: Activation function to use\n",
       "        (see [activations](../activations.md)).\n",
       "        If you don't specify anything, no activation is applied\n",
       "        (ie. \"linear\" activation: `a(x) = x`).\n",
       "    use_bias: Boolean, whether the layer uses a bias vector.\n",
       "    kernel_initializer: Initializer for the `kernel` weights matrix\n",
       "        (see [initializers](../initializers.md)).\n",
       "    bias_initializer: Initializer for the bias vector\n",
       "        (see [initializers](../initializers.md)).\n",
       "    kernel_regularizer: Regularizer function applied to\n",
       "        the `kernel` weights matrix\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    bias_regularizer: Regularizer function applied to the bias vector\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    activity_regularizer: Regularizer function applied to\n",
       "        the output of the layer (its \"activation\").\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    kernel_constraint: Constraint function applied to the kernel matrix\n",
       "        (see [constraints](../constraints.md)).\n",
       "    bias_constraint: Constraint function applied to the bias vector\n",
       "        (see [constraints](../constraints.md)).\n",
       "\n",
       "# Input shape\n",
       "    4D tensor with shape:\n",
       "    `(samples, channels, rows, cols)` if data_format='channels_first'\n",
       "    or 4D tensor with shape:\n",
       "    `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
       "\n",
       "# Output shape\n",
       "    4D tensor with shape:\n",
       "    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
       "    or 4D tensor with shape:\n",
       "    `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
       "    `rows` and `cols` values might have changed due to padding.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/keras/layers/convolutional.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Conv2DTranspose, DepthwiseConv2D\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(models.Sequential):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()   # 기본 특성을 상속한 부모 함수를 부름 models.Sequential.__init__(self) 와 동일\n",
    "      \n",
    "    \n",
    "        \"\"\"\n",
    "        첫 번째 은닉 계층 정의 부분에서는 자신의 형태뿐 아니라 입력 계층의 형태를 동시에 설정\n",
    "        아래 layers.Conv2D의 docs를 보면 fiters, kernel_size 이렇게 써있는데...\n",
    "        이해하면 결국 filter size를 의미하는 것이다.\n",
    "        \n",
    "        입력 계층의 형태는 객체의 초기화 변수인 input_shape를 따름\n",
    "        초기화 함수의 입력값이므로 모델의 인스턴스를 만들 때 정해집니다.\n",
    "        \n",
    "        합성곱 계층은 input_shape가 2차원 이미지들로 구성된다는 점, RGB로 여러 색상을 표현하기 때문에 input_shape의 길이가 3인 리스트\n",
    "        \"\"\"\n",
    "        self.add(layers.Conv2D(\n",
    "            32, kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            input_shape=input_shape))\n",
    "\n",
    "        \"\"\"\n",
    "        특이 사항 : 커널 수 64개\n",
    "        MaxPool2D : 합성곱을 한 뒤에 인접한 2 * 2 셀들을 묶어서 가장 큰 값만 내보내는 부속 계층\n",
    "        부속 계층은 학습을 통해 가중치가 바뀌는 형태는 아니지만 입력 신호를 특정한 형태로 변화시키는 계층\n",
    "        \n",
    "        dropout : 0.25\n",
    "        Flatten : 입력을 벡터로 바꿉니다. 2차원 벡터를 1차원 벡터로 변환 시킵니다.\n",
    "        \"\"\"\n",
    "        self.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "        self.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "        self.add(layers.Dropout(0.25))\n",
    "        self.add(layers.Flatten())\n",
    "\n",
    "        \"\"\"\n",
    "        앞의 두 개의 Conv2D layer는 이미지의 특징점을 잘 찾기 위한 것\n",
    "        \"\"\"\n",
    "        self.add(layers.Dense(128, activation='relu'))\n",
    "        self.add(layers.Dropout(0.5))\n",
    "        self.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "        self.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adadelta(),\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 분류 CNN을 위한 데이터 준비\n",
    "\n",
    "- x_train, x_test : 학습 및 성능 평가에 사용할 필기체 이미지 변수들의 배열\n",
    "- y_train, y_test : 학습과 성능 평가에 사용할 필기체 이미지의 레이블 정보의 배열\n",
    "\n",
    "#### DNN과 CNN의 데이터 준비 차이\n",
    "\n",
    "1. 이미지를 벡터화 하지 않고 그대로 사용, 2차원 이미지를 1차원으로 변환하지 않음\n",
    "2. 흑백 이미지의 채널 정보를 처리하려면 추가적인 차원을 이미지 데이터에 포함해야 합니다.\n",
    "  - 컬러 이미지는 RGB색상을 다루는 채널정보가 이미지 데이터에 이미 포함되어 있어 이미지를 나타내는 각 입력 데이터가 3차원으로 구성\n",
    "  - 흑백 이미지는 채널 정보가 존재하지 않아서 입력 데이터의 차원을 하나 더 추가해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "채널은 이미지 배열의 앞 단에 추가되어야 할 수도 있고, 뒷 단에 추가되어야 할 수도 있습니다.\n",
    "- 케라스의 시스템 파라미터인 'image_data_format'으로 지정\n",
    "\n",
    "```python3\n",
    "x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "- x_train.shape[0] : 샘플 수\n",
    "- 1 : 채널 수\n",
    "- img_rows : 이미지의 가로 길이\n",
    "- img_cols : 이미지의 세로 길이로 구성\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols) # 채널 이미지 정보가 앞에 들어감\n",
    "    \n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1) # 채널 이미지 정보가 끝에 들어감"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 학습 효과 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history, title=None):\n",
    "    # summarize history for accuracy\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Accracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_loss(history, title=None):\n",
    "    # summarize history for loss\n",
    "    if not isinstance(history, dict):\n",
    "        history = history.history\n",
    "\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training data', 'Validation data'], loc=0)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 분류 CNN 학습 및 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models, layers\n",
    "from keras import backend\n",
    "from keras import datasets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "2D convolution layer (e.g. spatial convolution over images).\n",
       "\n",
       "This layer creates a convolution kernel that is convolved\n",
       "with the layer input to produce a tensor of\n",
       "outputs. If `use_bias` is True,\n",
       "a bias vector is created and added to the outputs. Finally, if\n",
       "`activation` is not `None`, it is applied to the outputs as well.\n",
       "\n",
       "When using this layer as the first layer in a model,\n",
       "provide the keyword argument `input_shape`\n",
       "(tuple of integers, does not include the sample axis),\n",
       "e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
       "in `data_format=\"channels_last\"`.\n",
       "\n",
       "# Arguments\n",
       "    filters: Integer, the dimensionality of the output space\n",
       "        (i.e. the number output of filters in the convolution).\n",
       "    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
       "        width and height of the 2D convolution window.\n",
       "        Can be a single integer to specify the same value for\n",
       "        all spatial dimensions.\n",
       "    strides: An integer or tuple/list of 2 integers,\n",
       "        specifying the strides of the convolution along the width and height.\n",
       "        Can be a single integer to specify the same value for\n",
       "        all spatial dimensions.\n",
       "        Specifying any stride value != 1 is incompatible with specifying\n",
       "        any `dilation_rate` value != 1.\n",
       "    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
       "    data_format: A string,\n",
       "        one of `channels_last` (default) or `channels_first`.\n",
       "        The ordering of the dimensions in the inputs.\n",
       "        `channels_last` corresponds to inputs with shape\n",
       "        `(batch, height, width, channels)` while `channels_first`\n",
       "        corresponds to inputs with shape\n",
       "        `(batch, channels, height, width)`.\n",
       "        It defaults to the `image_data_format` value found in your\n",
       "        Keras config file at `~/.keras/keras.json`.\n",
       "        If you never set it, then it will be \"channels_last\".\n",
       "    dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
       "        the dilation rate to use for dilated convolution.\n",
       "        Can be a single integer to specify the same value for\n",
       "        all spatial dimensions.\n",
       "        Currently, specifying any `dilation_rate` value != 1 is\n",
       "        incompatible with specifying any stride value != 1.\n",
       "    activation: Activation function to use\n",
       "        (see [activations](../activations.md)).\n",
       "        If you don't specify anything, no activation is applied\n",
       "        (ie. \"linear\" activation: `a(x) = x`).\n",
       "    use_bias: Boolean, whether the layer uses a bias vector.\n",
       "    kernel_initializer: Initializer for the `kernel` weights matrix\n",
       "        (see [initializers](../initializers.md)).\n",
       "    bias_initializer: Initializer for the bias vector\n",
       "        (see [initializers](../initializers.md)).\n",
       "    kernel_regularizer: Regularizer function applied to\n",
       "        the `kernel` weights matrix\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    bias_regularizer: Regularizer function applied to the bias vector\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    activity_regularizer: Regularizer function applied to\n",
       "        the output of the layer (its \"activation\").\n",
       "        (see [regularizer](../regularizers.md)).\n",
       "    kernel_constraint: Constraint function applied to the kernel matrix\n",
       "        (see [constraints](../constraints.md)).\n",
       "    bias_constraint: Constraint function applied to the bias vector\n",
       "        (see [constraints](../constraints.md)).\n",
       "\n",
       "# Input shape\n",
       "    4D tensor with shape:\n",
       "    `(samples, channels, rows, cols)` if data_format='channels_first'\n",
       "    or 4D tensor with shape:\n",
       "    `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
       "\n",
       "# Output shape\n",
       "    4D tensor with shape:\n",
       "    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
       "    or 4D tensor with shape:\n",
       "    `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
       "    `rows` and `cols` values might have changed due to padding.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.7/site-packages/keras/layers/convolutional.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Conv2DTranspose, DepthwiseConv2D\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers.Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN modeling : classification\n",
    "\n",
    "class CNN(models.Sequential):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu',\n",
    "            input_shape=input_shape))\n",
    "        \n",
    "        self.add(layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(3,3),\n",
    "            activation='relu'))\n",
    "        self.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "        self.add(layers.Dropout(0.25))\n",
    "        self.add(layers.Flatten())\n",
    "        \n",
    "        self.add(layers.Dense(128, activation='relu'))\n",
    "        self.add(layers.Dropout(0.5))\n",
    "        self.add(layers.Dense(num_classes, activation='softmax'))\n",
    "        \n",
    "        self.compile(\n",
    "            loss=keras.losses.categorical_crossentropy,\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dataset for modeling : classification\n",
    "\n",
    "class DATA():\n",
    "    def __init__(self):\n",
    "        num_classes = 10\n",
    "        \n",
    "        (X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "        \n",
    "        img_rows, img_cols = X_train.shape[1:] # (60000, 28, 28) -> (28, 28)\n",
    "        \n",
    "        print(backend.image_data_format())\n",
    "        \n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "            X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "            input_shape = (1, img_rows, img_cols)\n",
    "            \n",
    "        else:\n",
    "            X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "            X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "            input_shape = (img_rows, img_cols, 1)\n",
    "            \n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        \n",
    "        X_train /= 255\n",
    "        X_test /= 255\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        to_categorical\n",
    "            keras.utils.to_categorical(y, num_classes=None, dtype='float32')\n",
    "            Converts a class vector (integers) to binary class matrix.\n",
    "\n",
    "            E.g. for use with categorical_crossentropy.\n",
    "\n",
    "            Arguments\n",
    "\n",
    "            y: class vector to be converted into a matrix (integers from 0 to num_classes).\n",
    "            num_classes: total number of classes.\n",
    "            dtype: The data type expected by the input, as a string (float32, float64, int32...)\n",
    "            Returns\n",
    "\n",
    "            A binary matrix representation of the input. The classes axis is placed last.\n",
    "        \"\"\"\n",
    "        \n",
    "        y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.X_train, self.y_train = X_train, y_train\n",
    "        self.X_test, self.y_test = X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "<__main__.DATA object at 0x7f356f4069b0>\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "result = DATA()\n",
    "print(result)\n",
    "print(result.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 83s 2ms/step - loss: 0.1931 - acc: 0.9416 - val_loss: 0.0628 - val_acc: 0.9822\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0954 - acc: 0.9727 - val_loss: 0.0623 - val_acc: 0.9830\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0926 - acc: 0.9744 - val_loss: 0.0674 - val_acc: 0.9821\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 83s 2ms/step - loss: 0.0972 - acc: 0.9731 - val_loss: 0.0606 - val_acc: 0.9826\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 86s 2ms/step - loss: 0.0991 - acc: 0.9728 - val_loss: 0.0784 - val_acc: 0.9795\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 84s 2ms/step - loss: 0.1096 - acc: 0.9714 - val_loss: 0.0690 - val_acc: 0.9827\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.1163 - acc: 0.9698 - val_loss: 0.0672 - val_acc: 0.9802\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 80s 2ms/step - loss: 0.1235 - acc: 0.9669 - val_loss: 0.0833 - val_acc: 0.9781\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 81s 2ms/step - loss: 0.1288 - acc: 0.9666 - val_loss: 0.0707 - val_acc: 0.9832\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 81s 2ms/step - loss: 0.1312 - acc: 0.9670 - val_loss: 0.1226 - val_acc: 0.9725\n",
      "10000/10000 [==============================] - 4s 367us/step\n",
      "\n",
      "Test loss: 0.12244330802645417\n",
      "Test accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4XNW59/3vrd6L5SLbsizbuMtNlhs21fQQqhMwBE7oLcAJT3hwSOdN8ZOT5IKcmJZgEoKBEBMISYghITQnuEhuyA03SZblrlGx+kjr/WON5JEsW6My2qOZ+3NduqTZs2fPPbI8v1lr7bW2GGNQSimlOhPmdAFKKaX6Bw0MpZRSPtHAUEop5RMNDKWUUj7RwFBKKeUTDQyllFI+0cBQSinlEw0MpZRSPtHAUEop5ZMIpwvoTQMHDjRZWVlOl6GUUv1Gfn7+MWPMIF/2DarAyMrKIi8vz+kylFKq3xCRIl/31S4ppZRSPtHAUEop5RMNDKWUUj7RwFBKKeUTDQyllFI+0cBQSinlEw0MpZRSPtHAUEqp7ijbBxt+D83NTlfSZ4Jq4l6/1OSG6iNQeRCqj0L8QEgZab+LOF2dUqojW16Hvz4CDVXQVA+z7nS6oj6hgeFPdZVQdRAqS6HqEFSV2mBo3XYQThwG08EnlMh4SMmE1JE2QNp/j0nq+9ejVKirr4J3HoXNr0LmPJBw+Mf34KyL7f/NIKeB0R3NTfaNvvKgVwi0/34QGk6c+tiYZEgcBklDYfAkSEy3PycOg/hBtpVRXgTlxeAqsj8X/tt+kvEWm9pxkKSMtEETGdM3v4ve0uSGunKodZ38ioiBrHMgLMR7Tks3Qd4LEBkHU74Ew2dq69MJpRth5e3gKoTzlsC5j9r/70/Pg788BLe8FfT/LhoY7dVXnT4AztQqCIuABM+b/+CJcNZCSBwKScO8vqdDVHzXazLGvoG6Cm2AtASJqwgOb4Wdf4emhraPSUg/feskaTiE++mf3l3f9k3fp69yqK/s+Hipo2DOPTD95tBqVTU3w+er4NNlULTatjib3bD2WUjNguxFNjwGT3C60uDX3AxrlsE/fwAJQ+Crf4ORZ9v7UjLh4ifgb4/Aht/BzK86Wqq/iTHG6Rp6TW5uruny4oPNzfDydVB5wAZD+0/y0LZV0Po9ve22+EHOfRJuboYTh9oGSXnxyZ8rS9oGXFiEDY02QZJ18nbCYGis8f3N3vt2Y83p65Rw2zI641fKyZ/Li2Dtc7B/LUQl2NCYcw+kjfH7r9QxDdWw6RVY8zSU7YXkEfY159xq79/+V/jsj7DvI/tvOmQKTFkE2ddDyghnaw9GVYfhrXthz79g4hfhi7+EuAFt92luht9fDQc2wv2f9rt/BxHJN8bk+rRvyAcGwMuLIDK2XWugh62CQNLUCBUlp7ZOWr5XH2n3AAHO8HcRHt35m31HX9GJ3WuyH8i3wVHwJ/spe+wlMPdeGH1B8HQBVJbCuuch70XbNTd8Jsz7Gky8quPWYNVh2PaWDY+S9XZb5tk2PCZdA/FpfVt/MNr1TxsW9VVw2U9g5m2n/3tzFcLTZ0PmHPjKn/rV36UGhuqahpq2LZITh233z+ne+CNjnamz6hDkLbdf1Udh0AT76XvqjRAV50xNPVW6ybYmCt6wLYYJV9qgGDHb9zedsr328Vv+CMd22hbkmAttl9X4KyA6wb+vIdi46+H9J+DTX9lxxkXLbTdzZ9b9Gt75Blz1K8i5xf919hINDBXc3PW2tbH2GTi4GWJSYOZ/2VMbUzKdrq5z7ccnohJgxi02/AaM6v5xjYHDBbbV8dkbtisyIhYmXGHDY8xCiIjqvdcRjI7thjdut39Xs+6CS/4/3z8gNTfD774Ih7bA/Wsgebh/a+0lGhgqNBgDxWtscGz/i9024UqYe5/nlMcA6xZoHZ94Bsr2QFKG7VrLudWOk/Wm5mbYv8aGx9a3oLbMBuvka2x4ZJ6tZ595M8aeKvu3b9hQvXoZTPhC149Tttd2TY06B256PfD+BjuggaFCT/l+WP9ryP+dHQNIn2qDI/t6iIh2trbKg57xieW2tmE5cHbL+ESk/5+/qRH2fGDDY8ffoLHanqiRfZ0Nj6HT+sUbm9/UVdqznD77oz2N+9rnetY6WPMMrFoC1zwD02/qvTr9RANDha6GGtjyB3v66dEd9uy1mbfBrDvsCQx96eBm+LRlfKLJfmKd9zUYMce5N+iGansa9mcrYfc/7EkEaWNtcExZFNxnoHWkJM/OragogQu+CQsegbDwnh2zuRl+ewUc2Qb3r7VnUgYwDQyljIG9H9rg+PxdOxA8+VrbBTR8pv+et7kZdr1rxycKP+m98Ql/qCmDbX+2gVa4GjC29TNlEUy+LuDf6HqkuRn+/SR88CPb2lr0gj3RoLcc3wPPnA2jz4fFrwV0Cy5gAkNELgOeAsKB3xhjlra7PxVYDowB6oDbjTEFnvu+DtyJPb/zM+A2Y0zdmZ5PA0N16Pge2yW0cYWdZ5Mx276BT7q697qEGqptH/inT58cn2iZPxGb0jvP4U8VB2Drn2y3zMHNgNh++ClfsvMPYlOdrrD3VB6EN++GfR/bDxFXPumff6P//Are+xZc+zxMu6H3j99LAiIwRCQc+By4GCgB1gOLjTHbvPb5H+CEMeYHIjIBWGaMWSgiw4HVwCRjTK2IvA68Y4z57ZmeUwNDnVFdpR10XvecHZxMHGa7qmbe1v15C5UH7dhJ3nI7cXFYDsx7oHfDqK8d/RwKVtrwKNsL4VF27suURTDuMudOq+4NO1fBW/eBuw4u/ynM+Ir/Pv03N8Hyy+DY5/DAOkgc4p/n6aFACYx5wPeNMZd6bn8TwBjzE699/gb8xBiz2nN7D3A2dsmSNcA0oBJ4C/ilMea9Mz2nBobySXMz7HrPnl2190O7ZtWUL9lB8iGTfTvGwS2226ngDTsOMPFK58cnepsxULrBnqJb8IZdTSAqwS57M/ZSGHuxXRWgP2isg39+z3ZRpk+B65fDoHH+f96jn8OzC+zv6oaXA/JvoyuB4c+1pIYD+71ulwBz2u2zGbgOWC0is4GRQIYxJl9EfgYUA7XAe52FhVI+CwuD8ZfZryPb7Szyza/Bxt/bs2Tm3AvjLz918LMlaD79lR2fiIy3LZQ598CA0c68Fn8SseM9w2fa+QiFq23L4/P37NgHAsNmwLhLbQtk6PTAPFX36E5YeQcc/gzm3g8Xfb/vzpwbNA4u/Bb847s2dKcs6pvn9RN/tjC+BFxqjLnTc/sWYLYx5kGvfZKwYxwzsOMUE7DjFsXAG8ANQDnwR2ClMeblDp7nbuBugMzMzJlFRUV+eT0qyNWUwYaX7GzdyhK7ptbsu22XRXgUbPbMnzi+267DNeceyPmv/jE+0duam+3ktF3v2RMKDuQDxi7Md9bFMO4Su2yL04tFGmP/Tf/+mF0J4JpnbLj1teYmeOES2733wNqAa5X1my6pdvsLsA+YClwKXGaMucNz363AXGPM/Wd6Tu2SUj3W5IYdf7WtjuL/2FZERJRnfGKG7Xbqz+MT/lB9DHb9wwbInvehrgLCImHkPE/X1SUwcGzfdsfUlsNfHrbrbY06D657vu9Pq/Z2ZAc8d45tuX75Jefq6ECgBEYEdtB7IXAAO+h9kzFmq9c+KUCNMaZBRO4CzjHG3Coic7BnT83Cdkn9FsgzxvzvmZ5TA0P1qtJNdkC7sdYuE5E5NyD7oANKk9uuLrzrXdt1dXS73Z6aZcNj3CUwcoF/r9dSvBbeuMNeiuDCb8PZDwdGV9knv4D3fwBf+q09OytABERgeAq5AngSe1rtcmPMj0TkXgBjzLOeVshLQBOwDbjDGOPyPPYH2C4pN7ARuNMYU3+m59PAUCrAuIpsy2PXe/Y0VnedvRDU6PNty2PsJb235lJzE3zyc/hwqV1i/PrlkOHHOTdd1eSGFy6yC30+sM5ehjkABExg9DUNDKUCWGMt7PvkZOujothuHzLFtjzGXgIZs7o307riAPzpbruY45Qvwxd+7vwYSkcOb4PnzrVzW770otPVABoYTpehlOqMMXbpls/fta2P4jV2+ZTYVDjrItt9ddbCUy9W1JHtf4W3v2bXzPrCz2Hajf6vvyc+/h/41w/hy7+HSVc5XY0GhlKqn6l12ava7fqH/ao5BhJmZ+WPu8QGyJDJbceQGmvh3W/Z650PnW6vW9Ef1sJqaoRfX2jHWB5Y51so+pEGhlKq/2pugtKNntbHu56lSrCnM4+92IZH4hB46wE7qH72g3Dhd/vXtT4OFcDz59nB7+t/42gpGhhKqeBRedCurPv5u3ZmfsMJuz1+MFz7jO3C6o8+XAof/gRufKV7197oJRoYSqng5K6H4k/tJ/SpXw64SXBd4m6wXVPVR+wV+hzqmupKYATAyclKKeWjiGh7Su7ZX+vfYQG2C+2aZVBzHFZ90+lqfKKBoZRSThk6zV60actrdiXdAKeBoZRSTjr3URg8Gf7633ZJkwCmgaGUUk5q6Zo6ccSeJhzANDCUUsppw2bAgv+GTS/beSgBSgNDKaUCwXmPwaAJ8PZDdsXfAKSBoZRSgSAiGq5+2l7Z8L1vO11NhzQwlFIqUGTMhLMfshd+2v2+09WcQgNDKaUCyfnfhIHj7AWg6iqdrqYNDQyllAokkTG2a6rygL0WeADRwFBKqUAzYhbMvR/yX7TrZwUIDQyllApEF34b0s6CPz8I9VVOVwNoYCilVGCKjIWrl0HFfvjn952uBtDAUEqpwJU5F+beB+t/Yy9v6zANDKWUCmQXfgdSR9nL0DZUO1qKBoZqdbCilrc2HuB/3t3B6+v3s6WknNqGJqfLUiq0RcXZrilXIbz/hKOlRDj67MpR+8tqWLuvjLV7j7N2XxnFZTWAvWxyy3W1wgSy0uKZMDSRCelJjE9PZGJ6EhmpsYSFyRmOrpTqNVnzYfY9sPZZmHQ1jDzbkTL0inshwhhD4fGa1nBYt6+MA+W1AKTERTI7awBzRqcxZ9QAxqcnUuKqZeehSrYfrGLHoUp2HqqiqKymNUjio8IZn57I+PQkJnqFSXJspIOvUqkg1lANT8+DsHC499+25dEL9BKtCmMMe46eYM3estZWxJGqegAGJkQxZ1Qac0YPYM6oNMYOTvCptVBd7+bzw1XsPFTFjkNVbD9YyY5DVVTUNrbuMyw5hglDbXhMSE9k4tAkRg2MJzJcez+V6rF9H8PvvghzH4DLftwrh+xKYGiXVJBobjbsPFzF2r3HWVdoWxDHTjQAMCQpmrmjTwbEmEHxiHS9Oyk+OoIZmanMyExt3WaM4XBlPds9rZAdnhD5ZNdRGpvsh5Go8DDGDE5gYnqiDZKhSUxMT2RQYnS36lAqZI06F2bdCWuehklX2bOo+pC2MPqppmbD9oOVrPF0Ma0vLKO8xn7SH54Sy5xRA1oDYmRaXJ+/MTe4m9l77AQ7DlZ5hUkVhyrrWvcZEB/F+CGJTBhqx0XGpycybkgisVHhfVqrUv1K/QnbNRURBfeutvM1ekC7pIJQY1MzBQcqWLevrDUgqurcAIxMi2POqAHMHmXHIEYM6J2+TX8or2lgh1dLZMch28VV22jPxhKBUWnxjE9PZPSgeBJjIomPjiAxOoL46AgSWr5iIoiPDicxOpKYyDBtqajQsvdDeOlqOPtBuOSHPTqUdkkFgQZ3M1tKylm7r4w1e4+TX+SixnOK6+hB8Vw5dRhzRw9g9qgBDE3u2SeMvpQSF8Xc0WnMHZ3Wuq252VBcVsOOQ54QOWiD5N2th2j24fNMmNAuSLyCxRM0iZ7tGj4qKIw+H2Z+FT5dBhOvtmtP9QFtYQSQjcUuPv78GGv3HWdDsYu6xmYAxg1JaB2knj1qAIMTYxyutG8YY6htbOJEnZsT9V5fdW6qG9ye7U1Ud3BfVZ277fZ6N778qXcUPulJMUwelsTk4clMHpYUMr9/FeDqKm3XVFQc3POJXeW2G7SF0Q/tO1bNtU//BxGYkJ7EjbMyPS2INAbERzldniNEhLioCOKiIhjcw2N1N3xO1LvZfrCSvxccaj3WoMRosoclMXlYMtnD7feM1Fhtmai+FZMEV/0SXr4OPloKF33f70+pgREg1u49DsA7D53DxKFJDlcTfHoaPlV1jWwrrWRraSUFpRVsK63k413HaPL0mSXFRDB5mG2BZHtaIqMHJRCukxuVP521EGbcAlteh3Mfhah4vz6dBkaAyCtyMSA+ignpiU6XojqQGBNpJzZ6jb3UNTax81BVa4hsLa3k92uKqHfbrsTYyHAmDE0k2xMkk4clMy49gegIPQtM9aJLfwymye9hARoYASO/yEVOZqp2a/QjMZHhTBuRwrQRKa3b3E3N7DlaTcEBGyBbSyt4a+MBfr+mCICIMGHskERPl5ZtjUwcmkR8tP5XVN0U03c9EvpXGgCOn6hn37Fqbpg1wulSVA9FhId5lkxJ5PqZdltzs2G/q4aCAzZACkor+deOI/wxvwQ4eSpxy6B6S4skNUTHrlTg0sAIAPlFLgBmjkztZE/VH4WFCSPT4hmZFs8Xpg4FTs6Q3+rpyio4UMGGIhd/2Vza+rhhyTFtQmTqiGQ9Q0s5SgMjAOQXuYgKD2PK8GSnS1F9RERIT44hPTmGhROHtG53VTew7WBla5dWQWkF/9x+uPWU4IzUWHIyU5mRmUJOZiqThiXpOl2qz2hgBIC8IhfZw5OIidTB0FCXGh/F/LMGMv+sga3bqj2n9m7aX86GYhfr9pXxtqclEh0RxtSMZE+IpJIzMkVbIcpvNDAcVu9u4rOSCv7r7JFOl6ICVHx0BLlZA8jNGtC6rbS8lg3FLjYUlbNxv4sX/13Icx/vBbQVovxHA8NhBQcqaGhqZubIAZ3vrJTHsJRYhqXEcuXUYYA9xXdraSUbi13aClF+49fAEJHLgKeAcOA3xpil7e5PBZYDY4A64HZjTIGIjAf+4LXraOC7xpgn/VmvE/IKdcBb9VxMZDgzR6a2+TvyboVsKHax/N/7aGzXCsnJTCFnZCoTh2orRHXOb4EhIuHAMuBioARYLyJvG2O2ee32OLDJGHOtiEzw7L/QGLMTmO51nAPAm/6q1Un5RS6y0uIYlBjtdCkqyHTcCqlgY7GOhaju8WcLYzaw2xizF0BEXgOuBrwDYxLwEwBjzA4RyRKRIcaYw177LAT2GGOK/FirI4wx5Be5OG/8IKdLUSHAtkIGtOn+1FaI6gp/BsZwYL/X7RJgTrt9NgPXAatFZDYwEsgAvAPjRuDV0z2JiNwN3A2QmZnZ86r7UOHxGo5XN5Cr4xfKIadrhbQEyNp9x9u0QqZlpHD5lHSum5FBcpxevz3U+DMwOlrjov0C00uBp0RkE/AZsBFwtx5AJAq4Cvjm6Z7EGPM88DzY5c17WHOfyissAyA3S8cvVGBo3woxxnCwoq61FbJm73F+8JdtLP37Dq6cOoyb5mSSk5miS9qECH8GRgngvdZFBlDqvYMxphK4DUDsX9w+z1eLy4EN7bqogsaGYhdJMRGcNSjB6VKU6pCInNIKKThQwSvrivnzxgO8saGECemJ3Dwnk2tmDCcxRlsdwcyfHZLrgbEiMsrTUrgReNt7BxFJ8dwHcCfwsSdEWizmDN1R/V1eoYuckamE6RLYqh/JHp7Mj6+dwtpvXcSPr51CeJjwnT9vZc6P32fJG1vYUlLudInKT/zWwjDGuEXka8C72NNqlxtjtorIvZ77nwUmAi+JSBN2MPyOlseLSBz2DKt7/FWjk8prGth15ARXTx/mdClKdUtCdAQ3zclk8ewRbCmp4JW1xfx5Uymvrd/PlOHJ3DQnk6umDdOVeIOIXqLVIf/acZjbf5vHq3fNZd6YtM4foFQ/UFnXyFsbD7BiTTE7D1eREB3BNTOGcdPskUwaphcGC0R6idZ+IL/IRXiYMN3rWgpK9XdJMZHcOi+LW+aOZEOxixVri3k9r4SX1xQzfUQKN83J5ItThxEbpeum9UfawnDIDc99Sm1jE29/bYHTpSjlV+U1Dbyx4QCvrC1iz9FqEmMiuD4ng5vmZDJuiF5h0mnawghwjU3NbC4pZ/Hs/jVvRKnuSImL4o4Fo7h9fhZr95XxytpiVqwt4rf/KWRWVio3zcnk8uyhulpzP6CB4YBtpZXUNTbrhD0VUkSEuaPTmDs6jeMnJrEyv4RX1xXz9T9s5gd/2cainAwWz8lkjJ5mHrA0MByQp1fYUyEuLSGae84bw13njOY/e47zyjrb4vjN6n3MHT2Am+eM5NLJ6URF6FIkgUQDwwH5RWUMT4klPVkXd1OhLSxMWDB2IAvGDuRIVR1/zLOtjgdf3UhafBRfyh3B4tkjGJkW73SpCg2MPmeMIa/QpafSKtXO4MQYHrjgLO47bwwf7zrKK2uL+fUne3n2oz2cM3YgN83O5KJJQ3QBRAdpYPSxElctR6rqydXuKKU6FBYmnD9+MOePH8yhijr+sH4/r60v5r4VGxiUGM0NuSO4YdYIhqfEBv0qCcYY6t3NVNY1UlXn9nw1tvleWecmIkx4aOFYv9ejgdHH8j3jFzkaGEp1Kj05hocvGssDF4zhw51HeWVdMcs+3M2vPtgNQGxkOHFR4cRGtXyPIN7r57jIcOKi7e24qAhiI8OJj/a6LyqcuOgIu3/kyf1iIsN6vKCiMYa6xmaq6hqpbPNG3/ZNv7L9tvq2+zU2dT71YXhKrAZGMMorKiMhOoIJ6TrrVSlfRYSHcdGkIVw0aQglrhre3XqYitpGahvcVDc0UdvQRE2DmxrPz64ae1/L7eoGN81dmHImAnGRnmCJCvf6iiA2Kpx4TyBFhgsn6tuHwMmf3Z08qQgkREWQGBNBYkwkiTERDEqIZvTAhDbbkrx+bvmeEB1BUkwkCTERhPdRS0sDo4/lFbqYkZnSZ//ASgWbjNQ47lgwqkuPaenaqW1ooqaxyQZNfZMNlEYbLDUNTdTUuz33N53c5hU8NQ1ujp2ob72vsamZhOgIz5t6JOlJMYwdbN/UE2JOBkFSTNtQaH3Tj4roV91qGhh9qKqukZ2Hq7gsO93pUpQKKSJCTGQ4MZHhaGdw93V6uoGI6OyyXrKxuBxjdP6FUqp/8uX8tLUi8kcRuUL0slo9klfkIkxgRqYGhlKq//ElMMZhL4F6C7BbRH4sIuP8W1Zw2lDkYkJ6Egl6fQClVD/UaWAY6x/GmMXYq+L9F7BORD4SkXl+rzBIuJua2Vjs0u4opVS/1elHXRFJA76CbWEcBh7EXmp1OvBHoGunK4SoHYeqqG5oIjdLA0Mp1T/50jfyKfB74BpjTInX9jwRedY/ZQWffF1wUCnVz/kSGOPNaa6yZIz5f71cT9DKL3KRnhTD8JRYp0tRSqlu8WXQ+z0Rab2OqIikisi7fqwpKOUX2fELPdFMKdVf+RIYg4wx5S03jDEuYLD/Sgo+BytqOVBeq91RSql+zZfAaBKR1muJishIIHguBN4H8grt+IUOeCul+jNfxjC+BawWkY88t88F7vZfScEnv8hFbGQ4E4fqgoNKqf6r08AwxqwSkRxgLiDA140xx/xeWRDJL3IxbUSyXvhFKdWv+foO1gQcASqASSJyrv9KCi7V9W62Hawkd6QuyaWU6t98mbh3J/AwkAFswrY0PgUu9G9pwWFzSTlNzYaZOn6hlOrnfGlhPAzMAoqMMRcAM4Cjfq0qiOR7BrxzRmhgKKX6N18Co84YUwcgItHGmB3AeP+WFTzyilyMG5JAclyk06UopVSP+HKWVIln4t5bwD9ExAWU+res4NDcbNhQ7OLKqcOcLkUppXrMl7OkrvX8+H0R+QBIBlb5taogsevICarq3OTqhD2lVBA4Y2CISBiwxRiTDWCM+ehM+6u28orKAF1wUCkVHM44hmGMaQY2e8/0Vr7LL3QxMCGKkWlxTpeilFI95ssYxlBgq4isA6pbNhpjrvJbVUEiTxccVEoFEV8C4wd+ryIIHamqo7ishlvmjnS6FKWU6hW+BEYxcNDr1NpYYIhfqwoCGzwXTMrR8QulVJDwZR7GH4Fmr9tNnm3qDPIKXURFhJE9XBccVEoFB18CI8IY09Byw/NzlP9KCg75xS6mZSQTHRHudClKKdUrfAmMoyLSOsAtIlcDulrtGdQ1NlFwoEK7o5RSQcWXwLgXeFxEikWkGHgMuMeXg4vIZSKyU0R2i8iSDu5PFZE3RWSLiKwTkWyv+1JEZKWI7BCR7SIyz9cX5bQtJRU0NhldoVYpFVR8mem9B5grIgmAGGOqfDmwiIQDy4CLgRJgvYi8bYzZ5rXb48AmY8y1IjLBs/9Cz31PAauMMYtEJAroN5MZdMKeUioYddrCEJEfi0iKMeaEMabK0yr4oQ/Hng3sNsbs9Yx7vAZc3W6fScD7AJ5FDbNEZIiIJGGv7PeC574G7+uKB7oNRS5GD4pnQLwO9SilgocvXVKXe79ZG2NcwBU+PG44sN/rdolnm7fNwHUAIjIbGIm97sZo7BLqL4rIRhH5jYjE+/CcjjPGkF/kYmamti6UUsHFl8AIF5HolhueeRjRZ9i/ddcOtpl2t5cCqSKyCXgQ2Ai4sV1lOcAzxpgZ2Bnmp4yBeOq5W0TyRCTv6FHnL9Ox52g1rppGcvWCSUqpIOPLxL2XgfdF5EXP7duA3/nwuBJghNftDNoti26MqfQcD7HrZ+zzfMUBJcaYtZ5dV3KawDDGPA88D5Cbm9s+kPpcfuv4hQ54K6WCiy+D3j8VkS3ARdhWwyps11Fn1gNjRWQUcAC4EbjJewfPdTZqPGMcdwIfe0KkUkT2i8h4Y8xO7ED4NvqB/CIXKXGRjBnUL3rQlFLKZ760MAAOYWd7fxnbAnijswcYY9wi8jXgXSAcWG6M2Soi93rufxaYCLwkIk3YQLjD6xAPAis8Z0jtxdMSCXR5nvELXXBQKRVsThsYIjIO2ypYDBwH/oA9rfYCXw9ujHkHeKfdtme9fv4UGHuax24Ccn19rkBQVt3A3qPVLJqZ4XQpSinV687UwtgBfAJ80RizG0BEvt4nVfVTLQsO6oQ9pVQwOtNZUtdju6I+EJFfi8hCOj7zSXnkFbmIDBemZiQ7XYpSSvW60waGMeZNY8zx3mXcAAAUwElEQVQNwATgQ+DrwBAReUZELumj+vqV/KIyJg9LJiZSFxxUSgWfTudhGGOqjTErjDFXYk+N3cRpTnENZfXuJjaXVJCry4EopYKULxP3WhljyowxzxljLvRXQf3V1tJKGtzNOmFPKRW0uhQY6vTyC/UKe0qp4KaB0UvyisrIHBDH4MQYp0tRSim/0MDoBS0LDur4hVIqmGlg9ILishqOnWhgpo5fKKWCmAZGL8jzjF/oBZOUUsFMA6MX5BW5SIyJYNzgRKdLUUopv9HA6AUbilzkZKYSFqYT4ZVSwUsDo4cqahv5/EiVDngrpYKeBkYPbSh2YYyOXyilgp8GRg/lF7oIDxOmZ6Y4XYpSSvmVBkYP5Re5mDQ0ibgoX69FpZRS/ZMGRg80NjWzaX+5dkcppUKCBkYPbD9YSW1jkwaGUiokaGD0QMuEPV2hVikVCjQweiC/2MXwlFiGJsc6XYpSSvmdBkY3GWPIL3TpcuZKqZChgdFNB8prOVRZpxP2lFIhQwOjm/KLdMFBpVRo0cDopvwiF/FR4UxI1wUHlVKhQQOjm/IKXUzPTCEiXH+FSqnQoO923XCi3s2OQ5XMHDnA6VKUUqrPaGB0w6bicpoNOuCtlAopGhjdkFdUhgi64KBSKqRoYHRDfpGL8UMSSYqJdLoUpZTqMxoYXdTUbNhYXK7LgSilQo4GRhftPFTFiXo3uTrgrZQKMRoYXZRfVAbohD2lVOjRwOiivCIXgxOjyUjVBQeVUqFFA6OL8otc5GalIiJOl6KUUn1KA6MLDlfWUeKq1Ql7SqmQpIHRBS0XTNLxC6VUKNLA6IK8ojJiIsOYPCzJ6VKUUqrPaWB0wYYiF9MyUojUBQeVUiHIr+98InKZiOwUkd0isqSD+1NF5E0R2SIi60Qk2+u+QhH5TEQ2iUieP+v0RW1DE1tLK7U7SikVsiL8dWARCQeWARcDJcB6EXnbGLPNa7fHgU3GmGtFZIJn/4Ve919gjDnmrxq7YtP+ctzNRmd4K6VClj9bGLOB3caYvcaYBuA14Op2+0wC3gcwxuwAskRkiB9r6rYNxXbAOydTA0MpFZr8GRjDgf1et0s827xtBq4DEJHZwEggw3OfAd4TkXwRuduPdfokr7CMsYMTSImLcroUpZRyhD8Do6OZbabd7aVAqohsAh4ENgJuz33zjTE5wOXAAyJybodPInK3iOSJSN7Ro0d7qfS2mpsN+UUuHb9QSoU0fwZGCTDC63YGUOq9gzGm0hhzmzFmOnArMAjY57mv1PP9CPAmtovrFMaY540xucaY3EGDBvX+qwB2Hz1BZZ1bA0MpFdL8GRjrgbEiMkpEooAbgbe9dxCRFM99AHcCHxtjKkUkXkQSPfvEA5cABX6s9Yzyi+z4RW6WzvBWSoUuv50lZYxxi8jXgHeBcGC5MWariNzruf9ZYCLwkog0AduAOzwPHwK86VmvKQJ4xRizyl+1diav0EVafBRZaXFOlaCUUo7zW2AAGGPeAd5pt+1Zr58/BcZ28Li9wDR/1tYV+UVl5IzUBQeVUqFNpyx34mhVPYXHa8jV8QulVIjTwOhEy/wLnbCnlAp1GhidyC9yERUexuRhyU6XopRSjtLA6EReYRlTMpKJiQx3uhSllHKUBsYZ1DU2UXCgUscvlFIKDYwzKjhQQUNTs07YU0opNDDOKM8zYS9HA0Mppfw7D6O/yyt0MWpgPAMTop0uRamA0NjYSElJCXV1dU6XorooJiaGjIwMIiMju30MDYzTMMawodjFhRMGO12KUgGjpKSExMREsrKydCJrP2KM4fjx45SUlDBq1KhuH0e7pE5j37FqyqobdMBbKS91dXWkpaVpWPQzIkJaWlqPW4YaGKfRMn6hA95KtaVh0T/1xr+bBsZp5Be6SI6NZMygBKdLUUp5HD9+nOnTpzN9+nTS09MZPnx46+2GhgafjnHbbbexc+fOM+6zbNkyVqxY0Rslt/HPf/6Ta6655oz7bNiwgVWrHFtr9Yx0DOM08ovtBZPCwvTTlFKBIi0tjU2bNgHw/e9/n4SEBL7xjW+02ccYgzGGsLCOPw+/+OKLnT7PAw880PNiu2nDhg0UFBRw2WWXOVbD6WgLowPlNQ3sPnJCu6OU6id2795NdnY29957Lzk5ORw8eJC7776b3NxcJk+ezBNPPNG674IFC9i0aRNut5uUlBSWLFnCtGnTmDdvHkeOHAHg29/+Nk8++WTr/kuWLGH27NmMHz+e//znPwBUV1dz/fXXM23aNBYvXkxubm5rmHn729/+xvjx41mwYAF//vOfW7evWbOGefPmMWPGDObPn8+uXbuora3liSeeYMWKFUyfPp2VK1d2uJ9TtIXRgXwdv1CqUz/4y1a2lVb26jEnDUvie1+c3K3Hbtu2jRdffJFnn7VXUFi6dCkDBgzA7XZzwQUXsGjRIiZNmtTmMRUVFZx33nksXbqURx55hOXLl7NkyZJTjm2MYd26dbz99ts88cQTrFq1iv/93/8lPT2dN954g82bN5OTk3PK42pqarjnnnv46KOPGD16NIsWLWq9b+LEiaxevZrw8HBWrVrFt7/9bf7whz/w3e9+l4KCgtbAqqio6HA/J2hgdCC/yEVEmDAtI8XpUpRSPhozZgyzZs1qvf3qq6/ywgsv4Ha7KS0tZdu2bacERmxsLJdffjkAM2fO5JNPPunw2Nddd13rPoWFhQCsXr2axx57DIBp06YxefKpQbdt2zbGjRvHmDFjALj55pt56aWXACgvL+fWW29lz549Z3xdvu7XFzQwOpBX5GLy8GRio3TBQaVOp7stAX+Jj49v/XnXrl089dRTrFu3jpSUFL7yla90eEppVFRU68/h4eG43e4Ojx0dHX3KPsYYn+o63dlJ3/rWt7j00ku5//772b1792nHLHzdry/oGEY7De5mNu8vZ2amdkcp1V9VVlaSmJhIUlISBw8e5N133+3151iwYAGvv/46AJ999hnbtm07ZZ9Jkybx+eefs2/fPowxvPrqq633VVRUMHz4cAB++9vftm5PTEykqqqq0/2coIHRztbSCurdzXrBJKX6sZycHCZNmkR2djZ33XUX8+fP7/XnePDBBzlw4ABTp07l5z//OdnZ2SQnt71uTlxcHM8++yyXX34555xzDqNHj26977HHHuPRRx89pbYLL7yQzZs3M2PGDFauXHna/Zwgvjar+oPc3FyTl5fXo2P85pO9/PBv21n3+EIGJ8X0UmVKBYft27czceJEp8sICG63G7fbTUxMDLt27eKSSy5h165dREQEbk9/R/9+IpJvjMn15fGB+8ockl/kYsSAWA0LpdQZnThxgoULF+J2uzHG8NxzzwV0WPSG4H51XWSMIa/IxfwxaU6XopQKcCkpKeTn5ztdRp/SMQwv+8tqOVpVz8ysAU6XopRSAUcDw0t+cRmArlCrlFId0MDwklfoIjE6gnFDEp0uRSmlAo4Ghpf8IhfTM1MI1wUHlVLqFBoYHpV1jew8XEXuSB2/UCpQnX/++adMwnvyySe5//77z/i4hAR7mYLS0tI26zm1P3Znp+U/+eST1NTUtN6+4oorKC8v96X0Lmmp93TKy8t5+umne/15O6OB4bGxuBxj0Al7SgWwxYsX89prr7XZ9tprr7F48WKfHj9s2DBWrlzZ7edvHxjvvPMOKSl9v+acBobD8gvLCBOYNkIXHFQqUC1atIi//vWv1NfXA1BYWEhpaSkLFixonReRk5PDlClT2iwl3qKwsJDs7GwAamtrufHGG5k6dSo33HADtbW1rfvdd999rUujf+973wPgl7/8JaWlpVxwwQVccMEFAGRlZXHs2DEAfvGLX5CdnU12dnbrSrOFhYVMnDiRu+66i8mTJ3PJJZe0eZ4W+/btY968ecyaNYvvfOc7rdtP95qWLFnCnj17mD59Oo8++qhPr7036DwMj7wiFxOHJpEQrb8SpXzy9yVw6LPePWb6FLh86WnvTktLY/bs2axatYqrr76a1157jRtuuAERISYmhjfffJOkpCSOHTvG3Llzueqqq067+N8zzzxDXFwcW7ZsYcuWLW2WJ//Rj37EgAEDaGpqYuHChWzZsoWHHnqIX/ziF3zwwQcMHDiwzbHy8/N58cUXWbt2LcYY5syZw3nnnUdqaiq7du3i1Vdf5de//jVf/vKXeeONN/jKV77S5vEPP/ww9913H7feeivLli1r3X6617R06VIKCgpar7/hdru79Nq7S1sYgLupmU37y/V0WqX6Ae9uKe/uKGMMjz/+OFOnTuWiiy7iwIEDHD58+LTH+fjjj1vfuKdOncrUqVNb73v99dfJyclhxowZbN26tcOFBb2tXr2aa6+9lvj4eBISErjuuutal0ofNWoU06dPB9ouj+7t3//+d+vruOWWW1q3+/qauvrau0s/TgM7DlVR09CkE/aU6ooztAT86ZprruGRRx5hw4YN1NbWtrYMVqxYwdGjR8nPzycyMpKsrKwOlzT31tEn8H379vGzn/2M9evXk5qayle/+tVOj3OmNflalkYHuzx6R11Sp6vF19fUndfeHdrCAPIK7YQ9vcKeUoEvISGB888/n9tvv73NYHdFRQWDBw8mMjKSDz74gKKiojMe59xzz2XFihUAFBQUsGXLFsAujR4fH09ycjKHDx/m73//e+tj2i897n2st956i5qaGqqrq3nzzTc555xzfH5N8+fPb201tdR0ptfU0RLoXXnt3aWBgR2/GJocw/CUWKdLUUr5YPHixWzevJkbb7yxddvNN99MXl4eubm5rFixggkTJpzxGPfddx8nTpxg6tSp/PSnP2X27NmAvXrejBkzmDx5MrfffnubZcXvvvtuLr/88tZB7xY5OTl89atfZfbs2cyZM4c777yTGTNm+Px6nnrqKZYtW8asWbOoqKjo9DWlpaUxf/58srOzefTRR7v82rtLlzcHzv7J++SMTOVXN516TV6l1Em6vHn/psub91C9u4mzzxrIOWMHdr6zUkqFsJAPjOiIcH72pWlOl6GUUgFPxzCUUkr5RANDKdUlwTTuGUp649/Nr4EhIpeJyE4R2S0iSzq4P1VE3hSRLSKyTkSy290fLiIbReSv/qxTKeWbmJgYjh8/rqHRzxhjOH78ODExPbv0tN/GMEQkHFgGXAyUAOtF5G1jjPeUyceBTcaYa0Vkgmf/hV73PwxsB5L8VadSyncZGRmUlJRw9OhRp0tRXRQTE0NGRkaPjuHPQe/ZwG5jzF4AEXkNuBrwDoxJwE8AjDE7RCRLRIYYYw6LSAbwBeBHwCN+rFMp5aPIyEhGjRrldBnKIf7skhoO7Pe6XeLZ5m0zcB2AiMwGRgItEfgk8H+BZj/WqJRSykf+DIyOlkls3/G5FEgVkU3Ag8BGwC0iVwJHjDH5nT6JyN0ikiciedpMVkop//Fnl1QJMMLrdgZQ6r2DMaYSuA1A7Mpb+zxfNwJXicgVQAyQJCIvG2Parglsj/E88DzYmd5+eB1KKaXw49IgIhIBfI4dxD4ArAduMsZs9donBagxxjSIyF3AOcaYW9sd53zgG8aYK314zqNAd1fdGggc6+Zjg43+LtrS30db+vs4KRh+FyONMYN82dFvLQxjjFtEvga8C4QDy40xW0XkXs/9zwITgZdEpAk7GH5HD5/TpxfdERHJ83U9lWCnv4u29PfRlv4+Tgq134VflwYxxrwDvNNu27NeP38KjO3kGB8CH/qhPKWUUl2gM72VUkr5RAPjpOedLiCA6O+iLf19tKW/j5NC6ncRVNfDUEop5T/awlBKKeWTkA+MzhZIDCUiMkJEPhCR7SKyVUQedromp+kCmCeJSIqIrBSRHZ6/kXlO1+QkEfm65/9JgYi8KiI9W9mvHwjpwPBaIPFy7LpWi0VkkrNVOcoN/B9jzERgLvBAiP8+4OQCmAqeAlYZYyYA0wjh34uIDAceAnKNMdnYqQM3nvlR/V9IBwZeCyQaYxqAlgUSQ5Ix5qAxZoPn5yrsG0L79b9ChtcCmL9xuhaniUgScC7wAoAxpsEYU+5sVY6LAGI9k5TjaLeSRTAK9cDwZYHEkCQiWcAMYK2zlThKF8A8aTRwFHjR00X3GxGJd7oopxhjDgA/A4qBg0CFMeY9Z6vyv1APDF8WSAw5IpIAvAH8t2e9r5DTlQUwQ0QEkAM8Y4yZAVQDITvmJyKp2N6IUcAwIF5ETlnrLtiEemB0ukBiqBGRSGxYrDDG/Mnpehw0H7sAZiG2q/JCEXnZ2ZIcVQKUGGNaWpwrsQESqi4C9hljjhpjGoE/AWc7XJPfhXpgrAfGisgoEYnCDlq97XBNjvGsGPwCsN0Y8wun63GSMeabxpgMY0wW9u/iXx2tlhwqjDGHgP0iMt6zaSFtL4YWaoqBuSIS5/l/s5AQOAnAr2tJBbrTLZDocFlOmg/cAnzmuUYJwOOeNcGUehBY4flwtRfPpQlCkTFmrYisBDZgzy7cSAjM+taZ3koppXwS6l1SSimlfKSBoZRSyicaGEoppXyigaGUUsonGhhKKaV8ooGhVBeISJOIbPL66rXZziKSJSIFvXU8pXpbSM/DUKobao0x050uQiknaAtDqV4gIoUi8v9EZJ3n6yzP9pEi8r6IbPF8z/RsHyIib4rIZs9Xy7IS4SLya891Ft4TkVjHXpRS7WhgKNU1se26pG7wuq/SGDMb+BV2pVs8P79kjJkKrAB+6dn+S+AjY8w07JpMLSsMjAWWGWMmA+XA9X5+PUr5TGd6K9UFInLCGJPQwfZC4EJjzF7PAo6HjDFpInIMGGqMafRsP2iMGSgiR4EMY0y91zGygH8YY8Z6bj8GRBpjfuj/V6ZU57SFoVTvMaf5+XT7dKTe6+cmdJxRBRANDKV6zw1e3z/1/PwfTl6682Zgtefn94H7oPW64Ul9VaRS3aWfXpTqmlivlXzBXuO65dTaaBFZi/0gttiz7SFguYg8ir1iXcsKrw8Dz4vIHdiWxH3YK7cpFbB0DEOpXuAZw8g1xhxzuhal/EW7pJRSSvlEWxhKKaV8oi0MpZRSPtHAUEop5RMNDKWUUj7RwFBKKeUTDQyllFI+0cBQSinlk/8f4dNsIu6NfrkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 분류 CNN 학습 및 성능 평가\n",
    "\n",
    "def main():\n",
    "    batch_size = 20\n",
    "    epochs = 10\n",
    "    \n",
    "    data = DATA()\n",
    "    model = CNN(data.input_shape, data.num_classes)\n",
    "    \n",
    "    history = model.fit(\n",
    "        data.X_train,\n",
    "        data.y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    score = model.evaluate(data.X_test, data.y_test)\n",
    "    print()\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    plot_loss(history)\n",
    "    plt.show()\n",
    "    plot_acc(history)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 분류 CNN 학습 및 성능 평가\n",
    "\n",
    "1. 분류 CNN 패키지 임포트\n",
    "2. 분류 CNN 모델링\n",
    "3. 분류 CNN을 위한 데이터 준비\n",
    "4. 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스\n",
    "5. 분류 CNN의 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 분류 CNN 패키지 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from kerasapp import skeras # 학습 곡선을 그리는 plot_loss(), plot_acc()를 모아 둔 파일\n",
    "from kerasapp import sfile # 학습 결과 저장하는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 분류 CNN 모델링\n",
    "\n",
    "#### LeNet\n",
    "- LeNet 신경망은 레쿤 교수 팀에서 만든 합성곱 방식 인공신경망\n",
    "- 합성곱 계층 두 개와 완전 연결 계층 하나로 구성\n",
    "\n",
    "![alt text](https://t1.daumcdn.net/cfile/tistory/2777003557AB5C0634)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers.Input?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 기본 구조\n",
    "\n",
    "```python\n",
    "class CNN(Model):\n",
    "    def __init__(model, nb_classes, in_shape=None):\n",
    "        model.nb_classes = nb_classes\n",
    "        model.in_shape = in_shape\n",
    "        model.build_model()\n",
    "        \n",
    "        super().__init__(model.x, model.y)\n",
    "        model.compile()\n",
    "```\n",
    "\n",
    "- 초기화 함수의 argu 로 nb_classes, in_shape의 값을 설정\n",
    "- build_model()로 모델을 만듬\n",
    "- 부모 클래스 초기화 함수 super().__init__()\n",
    "- 구성 모델을 compile함\n",
    "\n",
    "#### 입력 계층 및 은닉 계층 정의\n",
    "\n",
    "```python\n",
    "def build_model(model):\n",
    "    nb_classes = model.nb_classes\n",
    "    in_shape = model.in_shape\n",
    "    \n",
    "    x = Input(in_shape)\n",
    "    h = Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=in_shape)(x)\n",
    "    h = Conv2D(64, (3, 3), activation='relu')(h)\n",
    "    \n",
    "    h = MaxPooling2D(pool_size=(2,2))(h)\n",
    "    h = Dropout(0.25)(h)\n",
    "    h = Flatten()(h)\n",
    "    \n",
    "    z_cl = h\n",
    "    \n",
    "    h = Densc(128, activation='relu')(h)\n",
    "    h = Dropout(0.5)(h)\n",
    "    \n",
    "    z_fl = h\n",
    "    \n",
    "    y = Dense(nb_classes, activation='softmax', name='preds')(h)\n",
    "    model.cl_part = Model(x, z_cl)\n",
    "    model.fl_part = Model(x, z_fl)\n",
    "    \n",
    "    model.x, model.y = x, y\n",
    "```\n",
    "\n",
    "- 주어진 입력 이미지의 크기를 처리하는 입력 계층을 정의\n",
    "- 그 다음은 fully connected layeer로 구성된 hidden layer 두 개 정의\n",
    "- 두 hidden layer 모두 (3, 3) 크기로 구성된 convolution filter를 사용, activation='relu'\n",
    "\n",
    "#### flatten\n",
    "- 3차원 텐서를 1차원 벡터로 바꾸는 flatten\n",
    "- convolution은 3차원을 다루지만 fully connected layer는 1차원을 다루므로 변환 작업이 필요\n",
    "- 위의 코드에 넣어둠\n",
    "\n",
    "\n",
    "#### MaxPooling\n",
    "- (2,2) 크기의 블록 단위로 가장 큰 값을 찾아냄\n",
    "- 이 작업을 마치면 입력 크기가 가로 세로 두 축으로 각각 반씩 줄어듬\n",
    "- 결과가 어떻게 나올까...는 이 분 블로그 보고 참고 하였다\n",
    "  - https://seongkyun.github.io/study/2019/01/25/num_of_parameters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN은 모델의 일종이므로 케라스의 Model 클래스를 상속해서 만들었음\n",
    "\n",
    "class CNN(Model):\n",
    "    def __init__(model, nb_classes, in_shape=None):\n",
    "        model.nb_classes = nb_classes\n",
    "        model.in_shape = in_shape\n",
    "        model.build_model() # 모델 만들기\n",
    "        super().__init__(model.x, model.y)\n",
    "        model.compile()\n",
    "        \n",
    "    def build_model(model):\n",
    "        nb_classes = model.nb_classes\n",
    "        in_shape = model.in_shape\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        주어진 입력 이미지의 크기를 처리하는 입력 계층을 정의\n",
    "        그 다음은 완전 연결 계층으로 구성된 은닉 계층 두 개를 정의\n",
    "        두 은닉 계층 모두 (3, 3) 크기로 구성된 합성곱 필터를 사용\n",
    "        \"\"\"\n",
    "        x = Input(in_shape)\n",
    "        h = Conv2D(\n",
    "            32, \n",
    "            kernel_size=(3, 3), \n",
    "            activation='relu',\n",
    "            input_shape=in_shape)(x)\n",
    "        \n",
    "        h = Conv2D(\n",
    "            64,\n",
    "            (3, 3),\n",
    "            activation='relu')(h)\n",
    "        \n",
    "        \"\"\"\n",
    "        합성곱 계층의 처리 결과를 완전 연결 계층으로 보내기 위해 3차원 텐서를 1차원 벡터로 바꾸는 Flatten 작업\n",
    "        맥스풀링 작업이 마치고 나면 입력 크기가 가로 세로 두 축으로 각각 반씩 줄어듭니다.\n",
    "        여기까지 작업 한 것이 합성곱 계층의 출력임을 변수 z_c1을 사용해서 저장\n",
    "        이렇게 해두면 x와 z_c1 사이의 모델을 만들면 추후 합성곱 계층을 지난 결과를 별도로 분석 할 수 있음\n",
    "        \"\"\"\n",
    "        h = MaxPooling2D(pool_size=(2,2))(h)\n",
    "        h = Dropout(0.25)(h)\n",
    "        h = Flatten()(h)\n",
    "        z_c1 = h\n",
    "        \n",
    "        \"\"\"\n",
    "        완전 연결 계층은 128개 노드로 구성되었으며, Relu를 활성화 함수로 사용\n",
    "        출력 계층으로 나가기 전의 완전 연결 계층 출력도 별도로 저장, z_f1 = h\n",
    "        \"\"\"\n",
    "        h = Dense(128, activation='relu')(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        z_f1 = h\n",
    "        \n",
    "        \"\"\"\n",
    "        출력 계층을 nb_classes에 해당하는 만큼의 노드 수로 구성, 활성화 함수 소프트맥스로 지정\n",
    "        z_c1, z_f1을 이용해 부가적인 2가지 모델 생성\n",
    "        또한 본 모델을 만들 수 있도록 입력과 출력을 멤버 변수로 정의\n",
    "        \"\"\"\n",
    "        y = Dense(nb_classes, activation='softmax', name='preds')(h)\n",
    "        \n",
    "        model.c1_part = Model(x, z_c1)\n",
    "        model.f1_part = Model(x, z_f1)\n",
    "        \n",
    "        model.x, model.y = x, y\n",
    "        \n",
    "    def compile(model):\n",
    "        Model.compile(\n",
    "            model,\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adadelta',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 분류 CNN을 위한 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, X, y, nb_classes, scaling=True, test_size=0.2, random_state=0):\n",
    "        \"\"\"\n",
    "        X is originally vector. Hence, it will be transformed to 2D images with a channel.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        self.add_channels()에 입력값을 전달하는 방법보다는 self.X를 이용해 채널을 더하는 작업이 진행 됨\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.add_channels()        \n",
    "        X = self.X\n",
    "        \n",
    "        \n",
    "        # the data, shuffled and split between train and test sets\n",
    "        X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "        \n",
    "        print(X_train.shape, y_train.shape)\n",
    "        \n",
    "        # 이미지 데이터가 정수인 경우가 있으므로 32비트 실수로 변경\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        \n",
    "        if scaling:\n",
    "            # scaling to have (0, 1) for each feature(each pixel)\n",
    "            \n",
    "            scaler = MinMaxScaler()\n",
    "            \n",
    "            n = X_train.shape[0]\n",
    "            X_train = scaler.fit_transform(X_train.reshape(n, -1)).reshape(X_train.shape)\n",
    "            \n",
    "            n = X_test.shape[0]\n",
    "            X_test = scaler.transform(X_test.reshape(n, -1)).reshape(X_test.shape)\n",
    "            \n",
    "            self.scaler = scaler\n",
    "            \n",
    "        print('X_train shape:', X_train.shape)\n",
    "        print(X_train.shape[0], 'train samples')\n",
    "        print(X_test.shape[0], 'test samples')\n",
    "        \n",
    "        # convert class vectors to binary class matrices\n",
    "        \n",
    "        Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "        Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "        \n",
    "        self.X_train, self.X_test = X_train, X_test\n",
    "        self.Y_train, self.Y_test = Y_train, Y_test\n",
    "        self.y_train, self.y_test = y_train, y_test\n",
    "        \n",
    "    def add_channels(self):\n",
    "        X = self.X\n",
    "        \n",
    "        if len(X.shape) == 3:\n",
    "            N, img_rows, img_cols = X.shape\n",
    "            \n",
    "            # 케라스의 환경 변수인 image_dim_ordering이 'th', 즉 시에노 방식이라면 채널 정보를 길이 정보 바로 다음 두 번째 차원에 삽입\n",
    "            # 텐서플로우 방식일 경우 맨 마지막에 넣어줌\n",
    "            \n",
    "            if K.image_dim_ordering == 'th': # K is keras backend\n",
    "                X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n",
    "                input_shape = (1, img_rows, img_cols)\n",
    "            else:\n",
    "                X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n",
    "                input_shape = (img_rows, img_cols, 1)\n",
    "        else:\n",
    "            input_shape = X.shape[1:] # channel is already included\n",
    "            \n",
    "        self.X = X\n",
    "        self.input_shape = input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 분류 CNN의 학습 및 성능 평가를 위한 머신 클래스 구현\n",
    "\n",
    "Machine은 학습 및 성능 평가 코드가 들어 있는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine():\n",
    "    def __init__(self, X, y, nb_classes=2, fig=True):\n",
    "        self.nb_classes = nb_classes\n",
    "        self.set_data(X, y) # 데이터를 설정하는 함수\n",
    "        self.set_model() # model을 설정하는 함수\n",
    "        self.fig = fig # data 처리, model 생성 수행 결과를 그림으로 보여줄지를 클래스 전체에 영향을 주는 변수로 할당\n",
    "        \n",
    "    def set_data(self, X, y):\n",
    "        nb_classes = self.nb_classes\n",
    "        self.data = DataSet(X, y, nb_classes)\n",
    "        \n",
    "    def set_model(self):\n",
    "        nb_classes = self.nb_classes\n",
    "        data = self.data\n",
    "        self.model = CNN(nb_classes=nb_classes, in_shape=data.input_shape)\n",
    "        \n",
    "    def fit(self, nb_epoch=10, batch_size=128, verbose=1):\n",
    "        # nb_epoch 에포크, batch_size 학습 시 한 번에 처리할 블록 길이, verbose 진행 사항 표시\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        \n",
    "        history = model.fit(\n",
    "            data.X_train, data.Y_train,\n",
    "            batch_size=batch_size, epoch=nb_epoch,\n",
    "            verbose=verbose, validation_data=(data.X_test, data.Y_test)\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "            \n",
    "    # 학습과 성능 평가 전체를 진행하는 run() 함수\n",
    "    def run(self, nb_epoch=10, batch_size=128, verbose=1):\n",
    "        data = self.data\n",
    "        model = self,model\n",
    "        fig = self.fig\n",
    "        \n",
    "        history = self.fit(nb_epoch=nb_epoch, batch_size=batch_size, verbose=verbose)\n",
    "        score = model.evaluate(data.X_test, data.Y_test, verbose=0)\n",
    "        \n",
    "        print('Confusion matrix')\n",
    "        \n",
    "        Y_test_pred = model.predict(data.X_test, verbose=0)\n",
    "        \n",
    "        # 예측을 하게 되면 노드별로 이진값으로 결과가 출력되기 때문에 인덱스를 나타내는 정수 벡터로 바꿀 필요가 있다.\n",
    "        y_test_pred = np.argmax(Y_test_pred, axis=1)\n",
    "        print(metrics.confusion_matrix(data.y_test, y_test_pred))\n",
    "        \n",
    "        print('Test Score:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        \n",
    "        \n",
    "        # Save results\n",
    "        \n",
    "        suffix = sfile.unique_file_name('datatime')\n",
    "        foldname = 'output_' + suffix\n",
    "        skeras.save_history_history(\n",
    "            'history_history.npy', history.history, fold=foldname)\n",
    "        \n",
    "        # 학습 모델의 가중치 저장\n",
    "        model.save_weights(os.path.join(foldname, 'dl_model.h5'))\n",
    "        print('Output results are saved in', foldname)\n",
    "        \n",
    "        if fig:\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            skeras.plot_acc(history)\n",
    "            plt.subplot(1, 2, 2)\n",
    "            skeras.plot_loss(history)\n",
    "            plt.show()\n",
    "\n",
    "        self.history = history\n",
    "\n",
    "        return foldname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 분류 CNN의 학습 및 성능 평가 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import datasets\n",
    "from kerasapp import aicnn\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data_format을 channel_last로 가정했으므로 만약 channels_first로 설정된 경우 오류 내도록 코드 구현\n",
    "\n",
    "assert keras.backend.image_data_format() == 'channels_last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Returns the default image data format convention ('channels_first' or 'channels_last').\n",
       "\n",
       "# Returns\n",
       "    A string, either `'channels_first'` or `'channels_last'`\n",
       "\n",
       "# Example\n",
       "```python\n",
       "    >>> keras.backend.image_data_format()\n",
       "    'channels_first'\n",
       "```\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.7/site-packages/keras/backend/common.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras.backend.image_data_format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine(aicnn.Machine):\n",
    "    def __init__(self):\n",
    "        (X, y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "        super().__init__(X, y, nb_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    m = Machine()\n",
    "    m.run()\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
