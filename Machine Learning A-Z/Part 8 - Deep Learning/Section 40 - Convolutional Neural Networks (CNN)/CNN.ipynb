{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part8 - Deep Learning - Convolutional Neural Networks(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture note\n",
    "\n",
    "- reference : http://taewan.kim/post/cnn/\n",
    "\n",
    "#### image\n",
    "\n",
    "- image를 숫자로 표현하고 색을 구하고 표현\n",
    "\n",
    "\n",
    "#### convolution\n",
    "\n",
    "- convolution is a combined integration of the two functions and it shows you how one function modifies the other or modifies the shape\n",
    "- 자세한건 이미지 참고, 논문 참고\n",
    "\n",
    "- filter?\n",
    "  - feature detector를 이용하여 input image를 순회하여(**stride**) feature map을 완성\n",
    "  - 완성된 map에서 가장 높은 값을 지니는 부분을 확인한다.\n",
    "  \n",
    "- we create many feature maps to obtain our first convolution layer\n",
    "- filter를 이용하면 다양한 이미지 결과를 이끌어 낼 수 있다.(이미지 참고)\n",
    "\n",
    "#### ReLU layer\n",
    "\n",
    "- Rectifier\n",
    "  - image are highly non-linear\n",
    "  - 제시하는 논문 읽어 볼 것\n",
    "\n",
    "\n",
    "#### Pooling\n",
    "\n",
    "max pooling\n",
    "- feature map에서 특정 array내에서 가장 큰 값을 뽑아서 pooled feature map을 만든다.\n",
    "- reduce size, reduce number of parameter, preventing overfitting\n",
    "- research paper 보세요. 매우 간단하고 쉬워요. 꼭 보세요. ~10페이지임~\n",
    "\n",
    "#### Flattening\n",
    "\n",
    "pooled Feature Map에서 시작할거임\n",
    "- we flatten everything into a long vector\n",
    "- 1차원으로 만든다고 생각하면 편함\n",
    "\n",
    "#### Full connection\n",
    "\n",
    "- dog이 될 수 있는 뉴런에 대해 반복적으로 러닝이 진행되면서 결과를 도출한다.\n",
    "- cat도 동일한 원리로 작동된다.\n",
    "- 결국 확률적으로 선택하는 원리이다.\n",
    "\n",
    "\n",
    "#### summary\n",
    "\n",
    "- 이미지 넣기\n",
    "- 논문 넣기\n",
    "\n",
    "#### Softmax & Cross_entropy\n",
    "\n",
    "Softmax\n",
    "\n",
    "- soft max fuction or the mormalized exponential function is a generalization of the logistic function\n",
    "- [ref](https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&logNo=221021710286&proxyReferer=https%3A%2F%2Fwww.google.com%2F)\n",
    "- softmax를 이용(지수 함수)하면서 크고 작음의 차이가 더 벌어지게 되고, 분류 문제에서 더 올바른 결과를 이끌어 낼 수 있는 학습이 가능하다.\n",
    "\n",
    "Cross_entropy\n",
    "\n",
    "- [ref](http://blog.naver.com/PostView.nhn?blogId=gyrbsdl18&logNo=221013188633&redirect=Dlog&widgetTypeCall=true)\n",
    "- [ref](https://curt-park.github.io/2018-09-19/loss-cross-entropy)\n",
    "- 왜 이걸 쓰는게 mean squared error 쓰는 것보다 낫냐?\n",
    "  - 매우 작은 숫자들을 사용하게 되는데 그럴 때 매우 작은 수들로 연산을 하면 변화가 없음.\n",
    "  - cross_entropy를 사용하면 log scale을 사용하기 때문에 좀 더 연산에 최적화를 시킬 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 - Building the CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising the CNN\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wontaek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\", padding=\"same\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# step 1 - Convolution\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, \n",
    "                             border_mode = 'same', \n",
    "                             input_shape = (64, 64, 3), # CNN 할 때 이렇게 넣어줘야 함\n",
    "                             activation = 'relu'\n",
    "                            )\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 - Pooling\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a second convolutional layer\n",
    "# only need dimension, activation on second layer\n",
    "\n",
    "\n",
    "classifier.add(Convolution2D(32, 3, 3, \n",
    "                             border_mode = 'same', \n",
    "                             activation = 'relu'\n",
    "                            )\n",
    "              )\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - Flattening\n",
    "\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wontaek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/wontaek/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# step 4 - Full connection\n",
    "\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the CNN\n",
    "\n",
    "classifier.compile(optimizer='adam', \n",
    "                   loss='binary_crossentropy', \n",
    "                   metrics = ['accuracy']\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기억하자\n",
    "\n",
    "- keras document에 방문하면 기본적인 코드가 있다. 그걸 가져다 쓰면 된다.\n",
    "  - https://keras.io/preprocessing/image/#imagedatagenerator-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wontaek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/wontaek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8001 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=(64, 64), # cnn model target size\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 84s 337ms/step - loss: 0.5580 - acc: 0.7132 - val_loss: 0.6099 - val_acc: 0.6645\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 0.5210 - acc: 0.7426 - val_loss: 0.5112 - val_acc: 0.7555\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 0.4954 - acc: 0.7528 - val_loss: 0.5440 - val_acc: 0.7360\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 83s 333ms/step - loss: 0.4770 - acc: 0.7792 - val_loss: 0.4970 - val_acc: 0.7640\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 86s 343ms/step - loss: 0.4562 - acc: 0.7819 - val_loss: 0.4732 - val_acc: 0.7735\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 83s 334ms/step - loss: 0.4546 - acc: 0.7825 - val_loss: 0.4932 - val_acc: 0.7765\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 84s 337ms/step - loss: 0.4263 - acc: 0.8000 - val_loss: 0.5229 - val_acc: 0.7695\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 0.4169 - acc: 0.8067 - val_loss: 0.5144 - val_acc: 0.7720\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 0.4467 - acc: 0.7930 - val_loss: 0.4839 - val_acc: 0.7745\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 86s 342ms/step - loss: 0.4089 - acc: 0.8130 - val_loss: 0.4871 - val_acc: 0.7775\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 85s 341ms/step - loss: 0.3783 - acc: 0.8283 - val_loss: 0.5102 - val_acc: 0.7745\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 0.3744 - acc: 0.8263 - val_loss: 0.5501 - val_acc: 0.7560\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 84s 334ms/step - loss: 0.4007 - acc: 0.8180 - val_loss: 0.4829 - val_acc: 0.7835\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 82s 330ms/step - loss: 0.3467 - acc: 0.8479 - val_loss: 0.5202 - val_acc: 0.7845\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 83s 331ms/step - loss: 0.3419 - acc: 0.8438 - val_loss: 0.5435 - val_acc: 0.7740\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 83s 332ms/step - loss: 0.3166 - acc: 0.8654 - val_loss: 0.5433 - val_acc: 0.7905\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 83s 330ms/step - loss: 0.3057 - acc: 0.8673 - val_loss: 0.5778 - val_acc: 0.7800\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 83s 332ms/step - loss: 0.2799 - acc: 0.8820 - val_loss: 0.5447 - val_acc: 0.7910\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 80s 322ms/step - loss: 0.2791 - acc: 0.8786 - val_loss: 0.5587 - val_acc: 0.7985\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 81s 324ms/step - loss: 0.2588 - acc: 0.8946 - val_loss: 0.6042 - val_acc: 0.7775\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 0.2418 - acc: 0.9025 - val_loss: 0.6477 - val_acc: 0.7850\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 81s 323ms/step - loss: 0.2443 - acc: 0.8956 - val_loss: 0.5876 - val_acc: 0.7960\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 82s 330ms/step - loss: 0.2322 - acc: 0.9056 - val_loss: 0.6246 - val_acc: 0.7820\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 0.2134 - acc: 0.9129 - val_loss: 0.6915 - val_acc: 0.7695\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 79s 316ms/step - loss: 0.2117 - acc: 0.9135 - val_loss: 0.8034 - val_acc: 0.7580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12815e048>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=8000/32,\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2000/32)\n",
    "\n",
    "\n",
    "\n",
    "# classifier.fit_generator(\n",
    "#         training_set,\n",
    "#         steps_per_epoch=8000,\n",
    "#         epochs=25,\n",
    "#         validation_data=test_set,\n",
    "#         validation_steps=2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
