{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 데이터 다루기\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텍스트 데이터는 전처리를 잘 해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 문자열 데이터 타입\n",
    "\n",
    "자주 등장하는 유형 정리\n",
    "- 범주형 데이터 : 고정된 목록으록 구성(빨, 주, 노, 파...등등)\n",
    "- 범주형 의미를 연결시킬 수 있는 임의의 문자열 : 포용 가능한 범주를 정의해서 매핑\n",
    "- 구조화된 문자열 데이터 : 주소, 장소, 사람 이름 등 처리하기 어려운 것(이 책에서는 안 다룸)\n",
    "- 텍스트 데이터\n",
    "  - 데이터셋 : 말뭉치 corpus\n",
    "  - 하나의 텍스트를 의미하는 각 데이터 포인트를 문서라고 함 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 예제! 영화 리뷰 감성 분석\n",
    "- 영화 리뷰 데이터셋 imdb를 이용해서 분석해보자\n",
    "- ~~회사에서 데이터셋 받는데 세월이다...~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wontaek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/Users/wontaek/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files('aclImdb/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_train의 타입: <class 'list'>\n",
      "text_train의 길이: 75000\n",
      "text_train[6]:\n",
      " b'Gloomy Sunday - Ein Lied von Liebe und Tod directed by Rolf Sch\\xc3\\xbcbel in 1999 is a romantic, absorbing, beautiful, and heartbreaking movie. It started like Jules and Jim; it ended as one of Agatha Christie\\'s books, and in between it said something about love, friendship, devotion, jealousy, war, Holocaust, dignity, and betrayal, and it did better than The Black Book which is much more popular. It is not perfect, and it made me, a cynic, wonder in the end on the complexity of the relationships and sensational revelations, and who is who to whom but the movie simply overwhelmed me. Perfect or not, it is unforgettable. All four actors as the parts of the tragic not even a triangle but a rectangle were terrific. I do believe that three men could fell deeply for one girl as beautiful and dignified as Ilona in a star-making performance by young Hungarian actress Erica Marozs\\xc3\\xa1n and who would not? The titular song is haunting, sad, and beautiful, and no doubt deserves the movie been made about it and its effect on the countless listeners. I love the movie and I am surprised that it is so little known in this country. It is a gem.<br /><br />The fact that it is based on a story of the song that had played such important role in the lives of all characters made me do some research, and the real story behind the song of Love and Death seems as fascinating as the fictional one. The song was composed in 1930s by Rezs\\xc3\\xb6 Seress and was believed to have caused many suicides in Hungary and all over Europe as the world was moving toward the most devastating War of the last century. Rezs\\xc3\\xb6 Seress, a Jewish-Hungarian pianist and composer, was thrown to the Concentration Camp but survived, unlike his mother. In January, 1968, Seress committed suicide in Budapest by jumping out of a window. According to his obituary in the New York Times, \"Mr. Seres complained that the success of \"Gloomy Sunday\" actually increased his unhappiness, because he knew he would never be able to write a second hit.\" <br /><br />Many singers from all over the world have recorded their versions of the songs in different languages. Over 70 performers have covered the song since 1935, and some famous names include Billie Holiday, Paul Robeson, Pyotr Leschenko (in Russian, under title \"Mratschnoje Woskresenje\"), Bjork, Sarah McLachlan, and many more. The one that really got to me and made me shiver is by Diamanda Gal\\xc3\\xa1s, the Greek born American singer/pianist/performer with the voice of such tragic power that I still can\\'t get over her singing. Gal\\xc3\\xa1s has been described as \"capable of the most unnerving vocal terror\", and in her work she mostly concentrates on the topics of \"suffering, despair, condemnation, injustice and loss of dignity.\" When she sings the Song of Love and Death, her voice that could\\'ve belonged to the most tragic heroines of Ancient Greece leaves no hope and brings the horror and grief of love lost forever to the unbearable and incomparable heights.<br /><br />8.5/10'\n"
     ]
    }
   ],
   "source": [
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "print(\"text_train의 타입:\", type(text_train))\n",
    "print(\"text_train의 길이:\", len(text_train))\n",
    "print(\"text_train[6]:\\n\", text_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /br 문자열 정리\n",
    "\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 샘플 수 (훈련 데이터): [12500 12500 50000]\n"
     ]
    }
   ],
   "source": [
    "print(\"클래스별 샘플 수 (훈련 데이터):\", np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 문서 수: 25000\n",
      "클래스별 샘플 수 (테스트 데이터): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "reviews_test = load_files(\"aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "print(\"테스트 데이터의 문서 수:\", len(text_test))\n",
    "print(\"클래스별 샘플 수 (테스트 데이터):\", np.bincount(y_test))\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**우리가 풀려고 하는 문제**\n",
    "- 리뷰가 하나 주어졌을 때, 이 리뷰의 텍스트 내용을 보고 '양성'인지 '음성'인지 구분하는 것\n",
    "- 전형적인 이진 분류 문제\n",
    "- 텍스트 데이터는 머신러닝 모델이 다룰 수 있는 형태가 아님\n",
    "- 그래서 텍스트의 문자열 표현을 머신러닝 알고리즘에 적용할 수 있도록 수치 표현으로 바꿔야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 텍스트 데이터를 BOW로 표현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BOW**\n",
    "- bag of words\n",
    "- 장, 문단, 문장, 서식 같은 입력 텍스트의 구조 대부분을 잃고, 각 단어가 이 말뭉치에 있는 텍스트에 얼마나 많이 나타나는지만 헤아림\n",
    "- 텍스트를 담는 가방\n",
    "\n",
    "전체 말뭉치에 대해 BOW 표현을 계산하려면 다음 세 단계를 거쳐야 함\n",
    "- Tokenization : 토큰화, 각 문서를 문서에 포함된 단어(토큰)로 나눕니다. 예를 들어 공백이나 구두점 등을 기준으로 분리합니다.\n",
    "- 어휘 사전 구축 : 모든 문서에 나타난 모든 단어의 어휘를 모으고 번호를 매깁니다.(알파벳 순서 등)\n",
    "- 인코딩 : 어휘 사전의 단어가 문서마다 몇 번이나 나타나는지를 헤아립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3.1 샘플 데이터에 BOW 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어휘 사전의 크기: 13\n",
      "어휘 사전의 내용:\n",
      " {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"어휘 사전의 크기:\", len(vect.vocabulary_))\n",
    "print(\"어휘 사전의 내용:\\n\", vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW: <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "print(\"BOW:\", repr(bag_of_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOW 표현은 0이 아닌 값만 저장하는 Scipy 희소 행렬로 저장되어 있다.\n",
    "- 값이 0인 원소를 모두 저장하는 것음 메모리 낭비\n",
    "- toarray 메소드를 이용해서 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW의 밀집 표현:\n",
      " [[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW의 밀집 표현:\\n\", bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
